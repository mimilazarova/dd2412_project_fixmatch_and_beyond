{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqKZhkMlhUC/zqtpGY5uqY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimilazarova/dd2412_project_fixmatch_and_beyond/blob/main/WRN_28_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXaHCn3SUuY7"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "def regularized_padded_conv(*args, **kwargs):\n",
        "    return tf.keras.layers.Conv2D(*args, **kwargs, padding='same', kernel_regularizer=_regularizer,\n",
        "                                  kernel_initializer='he_normal', use_bias=False)\n",
        "\n",
        "\n",
        "def BN_ReLU(x):\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    return tf.keras.layers.ReLU()(x)\n",
        "\n",
        "\n",
        "def shortcut(x, filters, stride, mode):\n",
        "    if x.shape[-1] == filters:\n",
        "        return x\n",
        "    elif mode == 'B':\n",
        "        return regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "    elif mode == 'B_original':\n",
        "        x = regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "        return tf.keras.layers.BatchNormalization()(x)\n",
        "    elif mode == 'A':\n",
        "        return tf.pad(tf.keras.layers.MaxPool2D(1, stride)(x) if stride>1 else x,\n",
        "                      paddings=[(0, 0), (0, 0), (0, 0), (0, filters - x.shape[-1])])\n",
        "    else:\n",
        "        raise KeyError(\"Parameter shortcut_type not recognized!\")\n",
        "    \n",
        "\n",
        "def original_block(x, filters, stride=1, **kwargs):\n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(x)\n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "    \n",
        "    mode = 'B_original' if _shortcut_type == 'B' else _shortcut_type\n",
        "    x = shortcut(x, filters, stride, mode=mode)\n",
        "    return tf.keras.layers.ReLU()(x + c2)\n",
        "    \n",
        "    \n",
        "def preactivation_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "        \n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(flow)\n",
        "    if _dropout:\n",
        "        c1 = tf.keras.layers.Dropout(_dropout)(c1)\n",
        "        \n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c2\n",
        "\n",
        "\n",
        "def bootleneck_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "         \n",
        "    c1 = regularized_padded_conv(filters//_bootleneck_width, 1)(flow)\n",
        "    c2 = regularized_padded_conv(filters//_bootleneck_width, 3, strides=stride)(BN_ReLU(c1))\n",
        "    c3 = regularized_padded_conv(filters, 1)(BN_ReLU(c2))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c3\n",
        "\n",
        "\n",
        "def group_of_blocks(x, block_type, num_blocks, filters, stride, block_idx=0):\n",
        "    global _preact_shortcuts\n",
        "    preact_block = True if _preact_shortcuts or block_idx == 0 else False\n",
        "    \n",
        "    x = block_type(x, filters, stride, preact_block=preact_block)\n",
        "    for i in range(num_blocks-1):\n",
        "        x = block_type(x, filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Resnet(input_shape, n_classes, l2_reg=1e-4, group_sizes=(2, 2, 2), features=(16, 32, 64), strides=(1, 2, 2),\n",
        "           shortcut_type='B', block_type='preactivated', first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1},\n",
        "           dropout=0, cardinality=1, bootleneck_width=4, preact_shortcuts=True):\n",
        "    \n",
        "    global _regularizer, _shortcut_type, _preact_projection, _dropout, _cardinality, _bootleneck_width, _preact_shortcuts\n",
        "    _bootleneck_width = bootleneck_width # used in ResNeXts and bootleneck blocks\n",
        "    _regularizer = tf.keras.regularizers.l2(l2_reg)\n",
        "    _shortcut_type = shortcut_type # used in blocks\n",
        "    _cardinality = cardinality # used in ResNeXts\n",
        "    _dropout = dropout # used in Wide ResNets\n",
        "    _preact_shortcuts = preact_shortcuts\n",
        "    \n",
        "    block_types = {'preactivated': preactivation_block,\n",
        "                   'bootleneck': bootleneck_block,\n",
        "                   'original': original_block}\n",
        "    \n",
        "    selected_block = block_types[block_type]\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    flow = regularized_padded_conv(**first_conv)(inputs)\n",
        "    \n",
        "    if block_type == 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    for block_idx, (group_size, feature, stride) in enumerate(zip(group_sizes, features, strides)):\n",
        "        flow = group_of_blocks(flow,\n",
        "                               block_type=selected_block,\n",
        "                               num_blocks=group_size,\n",
        "                               block_idx=block_idx,\n",
        "                               filters=feature,\n",
        "                               stride=stride)\n",
        "    \n",
        "    if block_type != 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    flow = tf.keras.layers.GlobalAveragePooling2D()(flow)\n",
        "    outputs = tf.keras.layers.Dense(n_classes, kernel_regularizer=_regularizer)(flow)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "# If we want to load pre-trained weights\n",
        "def load_weights_func(model, model_name):\n",
        "    try: model.load_weights(os.path.join('saved_models', model_name + '.tf'))\n",
        "    except tf.errors.NotFoundError: print(\"No weights found for this model!\")\n",
        "    return model\n",
        "\n",
        "# Creating a wide ResNet for cifar-10 dataset\n",
        "def cifar_wide_resnet(N, K, block_type='preactivated', shortcut_type='B', dropout=0, l2_reg=2.5e-4):\n",
        "    assert (N-4) % 6 == 0, \"N-4 has to be divisible by 6\"\n",
        "    lpb = (N-4) // 6 # layers per block - since N is total number of convolutional layers in Wide ResNet\n",
        "    model = Resnet(input_shape=(32, 32, 3), n_classes=10, l2_reg=l2_reg, group_sizes=(lpb, lpb, lpb), features=(16*K, 32*K, 64*K),\n",
        "                   strides=(1, 2, 2), first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1}, shortcut_type=shortcut_type,\n",
        "                   block_type=block_type, dropout=dropout, preact_shortcuts=True)\n",
        "    return model\n",
        "\n",
        "# Specifying wide ResNet-28-2 model\n",
        "def WRN_28_2(shortcut_type='B', load_weights=False, dropout=0, l2_reg=2.5e-4):\n",
        "    model = cifar_wide_resnet(28, 2, 'preactivated', shortcut_type, dropout=dropout, l2_reg=l2_reg)\n",
        "    if load_weights: model = load_weights_func(model, 'cifar_WRN_28_10') # loading pre-trained weights\n",
        "    return model\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06AqVwlXATf"
      },
      "source": [
        "model = WRN_28_2()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mylA8exilz-Z",
        "outputId": "660b7bef-36ef-4abd-c561-573fa43818b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load CIFAR-10 dataset\n",
        "ds = tfds.load('cifar10', as_supervised=True, in_memory=True)\n",
        "#std = tf.reshape((0.2023, 0.1994, 0.2010), shape=(1, 1, 3))\n",
        "#mean = tf.reshape((0.4914, 0.4822, 0.4465), shape=(1, 1, 3))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:`in_memory` if deprecated and will be removed in a future version. Please use `ds = ds.cache()` instead.\n",
            "WARNING:absl:`in_memory` if deprecated and will be removed in a future version. Please use `ds = ds.cache()` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oo4M8tOfnQGJ"
      },
      "source": [
        "# Re-formatting the data so it fits the desired shapes by tf.keras.model\n",
        "\n",
        "# train and validation split (60000 samples total in CIFAR-10)\n",
        "x_train = np.zeros([50000, 32, 32, 3])\n",
        "y_train = np.zeros([50000, 1])\n",
        "x_val = np.zeros([10000, 32, 32, 3])\n",
        "y_val = np.zeros([10000, 1])\n",
        "\n",
        "i = 0\n",
        "j = 0\n",
        "for sample, label in ds[\"train\"].take(60000):\n",
        "  if i < 50000:\n",
        "    x_train[i] = np.asarray(sample)\n",
        "    y_train[i] = np.asarray(label)\n",
        "  else: \n",
        "    x_val[j] = np.asarray(sample)\n",
        "    y_val[j] = np.asarray(label)\n",
        "    j += 1\n",
        "  i += 1\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xv4u0QTlsy1",
        "outputId": "7d0031a3-69ff-4cec-82ef-1d4ba172011e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "# hyperparameters taken from cifar_training function in https://github.com/gahaalt/ResNets-in-tensorflow2/blob/master/cifar_training_tools.py\n",
        "lr_boundaries=[400, 32000, 48000, 64000]\n",
        "lr_values=[0.01, 0.1, 0.01, 0.001]\n",
        "schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=lr_boundaries[:-1], values=lr_values)\n",
        "opt = tf.keras.optimizers.SGD(schedule, momentum=0.9, nesterov=False)\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.SparseCategoricalAccuracy()\n",
        "model.compile(loss=loss_fn, optimizer=opt, metrics=metrics)\n",
        "\n",
        "tf.keras.utils.plot_model(model)\n",
        "\n",
        "#early_stopping = EarlyStopping(monitor='val_accuracy', verbose=1,\n",
        "#                               patience=7,\n",
        "#                               mode='max',\n",
        "#                               restore_best_weights=True)\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 5\n",
        "\n",
        "#callbacks_list = [early_stopping]\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
        "                    validation_data=(x_val, y_val),\n",
        "                    #steps_per_epoch=len(x_train) // batch_size,\n",
        "                    #callbacks=callbacks_list,\n",
        "                    epochs=epochs, verbose=1)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 58s 148ms/step - loss: 2.5499 - sparse_categorical_accuracy: 0.4326 - val_loss: 4.3120 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 2.0498 - sparse_categorical_accuracy: 0.5760 - val_loss: 4.7467 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 1.4905 - sparse_categorical_accuracy: 0.7121 - val_loss: 3.3884 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 57s 146ms/step - loss: 1.1893 - sparse_categorical_accuracy: 0.7736 - val_loss: 5.3283 - val_sparse_categorical_accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 57s 145ms/step - loss: 1.0061 - sparse_categorical_accuracy: 0.8070 - val_loss: 4.5232 - val_sparse_categorical_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}