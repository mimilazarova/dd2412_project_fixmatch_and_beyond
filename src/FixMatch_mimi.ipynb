{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FixMatch_mimi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimilazarova/dd2412_project_fixmatch_and_beyond/blob/main/src/FixMatch_mimi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwu53CIVxCUk",
        "outputId": "130c78f6-aa3f-4c79-c482-9c94ff1f2ea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmfb90N9fjlY",
        "outputId": "4a02c455-b8b0-4f61-9def-6ded441bb6d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "pip install tensorflow-addons==0.11.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/51/8e5bb7649ac136292aefef6ea0172d10cc23a26dcda093c62637585bc05e/tensorflow_addons-0.11.1-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 21.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 23.5MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 18.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 15.2MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 12.6MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 13.0MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 12.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 11.0MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 11.0MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 11.0MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 11.0MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153kB 11.0MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 245kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 256kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 286kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 317kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 337kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 348kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 368kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 399kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 409kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 430kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 440kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 460kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 471kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 491kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 501kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 512kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 522kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 532kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 542kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 563kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 573kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 583kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 593kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 604kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 614kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 624kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 634kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 645kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 665kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 675kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 686kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 696kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 706kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 716kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 727kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 737kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 747kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 768kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 778kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 788kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 798kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 808kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 819kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 829kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 839kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 849kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 860kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 870kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 880kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 890kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 901kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 911kB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 921kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 942kB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 952kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 962kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 972kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 983kB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 993kB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.0MB 11.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 11.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.11.1) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "  Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "Successfully installed tensorflow-addons-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrK1j-cwMj3Z"
      },
      "source": [
        "# All imports here\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from matplotlib import pyplot as plt\n",
        "import json\n",
        "from tensorflow.python.framework import constant_op\n",
        "from tensorflow.python.framework import ops\n",
        "from tensorflow.python.ops import math_ops\n",
        "import math"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLvGggx4rFVD",
        "outputId": "a14c27af-e094-4b24-b409-440579b596c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXaHCn3SUuY7"
      },
      "source": [
        "# this cell is for the wide ResNet\n",
        "def regularized_padded_conv(*args, **kwargs):\n",
        "    return tf.keras.layers.Conv2D(*args, **kwargs, padding='same', kernel_regularizer=_regularizer,\n",
        "                                  kernel_initializer='he_normal', use_bias=False)\n",
        "\n",
        "\n",
        "def BN_ReLU(x):\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    return tf.keras.layers.ReLU()(x)\n",
        "\n",
        "\n",
        "def shortcut(x, filters, stride, mode):\n",
        "    if x.shape[-1] == filters:\n",
        "        return x\n",
        "    elif mode == 'B':\n",
        "        return regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "    elif mode == 'B_original':\n",
        "        x = regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "        return tf.keras.layers.BatchNormalization()(x)\n",
        "    elif mode == 'A':\n",
        "        return tf.pad(tf.keras.layers.MaxPool2D(1, stride)(x) if stride>1 else x,\n",
        "                      paddings=[(0, 0), (0, 0), (0, 0), (0, filters - x.shape[-1])])\n",
        "    else:\n",
        "        raise KeyError(\"Parameter shortcut_type not recognized!\")\n",
        "    \n",
        "\n",
        "def original_block(x, filters, stride=1, **kwargs):\n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(x)\n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "    \n",
        "    mode = 'B_original' if _shortcut_type == 'B' else _shortcut_type\n",
        "    x = shortcut(x, filters, stride, mode=mode)\n",
        "    return tf.keras.layers.ReLU()(x + c2)\n",
        "    \n",
        "    \n",
        "def preactivation_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "        \n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(flow)\n",
        "    if _dropout:\n",
        "        c1 = tf.keras.layers.Dropout(_dropout)(c1)\n",
        "        \n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c2\n",
        "\n",
        "\n",
        "def bootleneck_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "         \n",
        "    c1 = regularized_padded_conv(filters//_bootleneck_width, 1)(flow)\n",
        "    c2 = regularized_padded_conv(filters//_bootleneck_width, 3, strides=stride)(BN_ReLU(c1))\n",
        "    c3 = regularized_padded_conv(filters, 1)(BN_ReLU(c2))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c3\n",
        "\n",
        "\n",
        "def group_of_blocks(x, block_type, num_blocks, filters, stride, block_idx=0):\n",
        "    global _preact_shortcuts\n",
        "    preact_block = True if _preact_shortcuts or block_idx == 0 else False\n",
        "    \n",
        "    x = block_type(x, filters, stride, preact_block=preact_block)\n",
        "    for i in range(num_blocks-1):\n",
        "        x = block_type(x, filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Resnet(input_shape, n_classes, l2_reg=1e-4, group_sizes=(2, 2, 2), features=(16, 32, 64), strides=(1, 2, 2),\n",
        "           shortcut_type='B', block_type='preactivated', first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1},\n",
        "           dropout=0, cardinality=1, bootleneck_width=4, preact_shortcuts=True):\n",
        "    \n",
        "    global _regularizer, _shortcut_type, _preact_projection, _dropout, _cardinality, _bootleneck_width, _preact_shortcuts\n",
        "    _bootleneck_width = bootleneck_width # used in ResNeXts and bootleneck blocks\n",
        "    _regularizer = tf.keras.regularizers.l2(l2_reg)\n",
        "    _shortcut_type = shortcut_type # used in blocks\n",
        "    _cardinality = cardinality # used in ResNeXts\n",
        "    _dropout = dropout # used in Wide ResNets\n",
        "    _preact_shortcuts = preact_shortcuts\n",
        "    \n",
        "    block_types = {'preactivated': preactivation_block,\n",
        "                   'bootleneck': bootleneck_block,\n",
        "                   'original': original_block}\n",
        "    \n",
        "    selected_block = block_types[block_type]\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    flow = regularized_padded_conv(**first_conv)(inputs)\n",
        "    \n",
        "    if block_type == 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    for block_idx, (group_size, feature, stride) in enumerate(zip(group_sizes, features, strides)):\n",
        "        flow = group_of_blocks(flow,\n",
        "                               block_type=selected_block,\n",
        "                               num_blocks=group_size,\n",
        "                               block_idx=block_idx,\n",
        "                               filters=feature,\n",
        "                               stride=stride)\n",
        "    \n",
        "    if block_type != 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    flow = tf.keras.layers.GlobalAveragePooling2D()(flow)\n",
        "    outputs = tf.keras.layers.Dense(n_classes, kernel_regularizer=_regularizer)(flow)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_weights_func(model, model_name):\n",
        "    try: model.load_weights(os.path.join('saved_models', model_name + '.tf'))\n",
        "    except tf.errors.NotFoundError: print(\"No weights found for this model!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def cifar_wide_resnet(N, K, block_type='preactivated', shortcut_type='B', dropout=0, l2_reg=2.5e-4):\n",
        "    assert (N-4) % 6 == 0, \"N-4 has to be divisible by 6\"\n",
        "    lpb = (N-4) // 6 # layers per block - since N is total number of convolutional layers in Wide ResNet\n",
        "    model = Resnet(input_shape=(32, 32, 3), n_classes=10, l2_reg=l2_reg, group_sizes=(lpb, lpb, lpb), features=(16*K, 32*K, 64*K),\n",
        "                   strides=(1, 2, 2), first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1}, shortcut_type=shortcut_type,\n",
        "                   block_type=block_type, dropout=dropout, preact_shortcuts=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def WRN_28_2(shortcut_type='B', load_weights=False, dropout=0, l2_reg=2.5e-4):\n",
        "    model = cifar_wide_resnet(28, 2, 'preactivated', shortcut_type, dropout=dropout, l2_reg=l2_reg)\n",
        "    if load_weights: model = load_weights_func(model, 'cifar_WRN_28_10')\n",
        "    return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hfy2W4iGscd"
      },
      "source": [
        "# This cell is for CTAugment\n",
        "\n",
        "class CTAugment:\n",
        "\n",
        "  def __init__(self, n_classes, decay=0.99, threshold=0.80, depth=2, n_bins=17):\n",
        "    self.decay = decay\n",
        "    self.threshold = threshold\n",
        "    self.depth = depth\n",
        "    self.n_bins = n_bins\n",
        "    self.n_classes = n_classes\n",
        "    self.xforms = []\n",
        "    # self.bins = [[]]\n",
        "    # self.weights = [[]]\n",
        "\n",
        "    self.AUG_DICT = {\n",
        "        \"autocontrast\": {\"f\": self.autocontrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"blur\": {\"f\": self.blur, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"brightness\": {\"f\": self.brightness, \"weight\":[np.ones(self.n_bins)*1.0]},\n",
        "        \"color\": {\"f\": self.color, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"contrast\": {\"f\": self.contrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"cutout\": {\"f\": self.cutout, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"equalize\": {\"f\": self.equalize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"invert\": {\"f\": self.invert, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"identity\": {\"f\": self.identity, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"posterize\": {\"f\": self.posterize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"rescale\": {\"f\": self.rescale, \"weight\": [np.ones(self.n_bins)*1.0, np.ones(6)*1.0]},\n",
        "        \"rotate\": {\"f\": self.rotate, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"sharpness\": {\"f\": self.sharpness, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_x\": {\"f\": self.shear_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_y\": {\"f\": self.shear_y, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"smooth\": {\"f\": self.smooth, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"solarize\": {\"f\": self.solarize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_x\": {\"f\": self.translate_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_y\": {\"f\": self.translate_y, \"weight\": [np.ones(self.n_bins)*1.0]}\n",
        "    }\n",
        "    self.N = len(self.AUG_DICT.keys())\n",
        "    self.options = list(self.AUG_DICT.keys())\n",
        "\n",
        "    self.batch_choices = []\n",
        "    self.batch_bins = []\n",
        "\n",
        "  def weight_to_p(self, weight):\n",
        "        p = weight + (1 - self.decay)  # Avoid to have all zero.\n",
        "        p = p / p.max()\n",
        "        p[p < self.threshold] = 0\n",
        "        return p/np.sum(p)\n",
        "\n",
        "  def augment(self, x, uniform_bin_sampling=False):\n",
        "    aug_x = Image.fromarray(np.uint8(x))#255*x))\n",
        "\n",
        "    choices = [self.options[i] for i in np.random.choice(np.arange(self.N), self.depth, replace=False)]\n",
        "    bins = []\n",
        "\n",
        "    for k in range(self.depth):\n",
        "        choice_key = choices[k]\n",
        "        \n",
        "        transformation = self.AUG_DICT[choice_key][\"f\"]\n",
        "        # sample bins\n",
        "        if uniform_bin_sampling:\n",
        "          p = np.ones(self.N)/self.N\n",
        "        else:\n",
        "          w = self.AUG_DICT[choice_key][\"weight\"][0]\n",
        "          p = self.weight_to_p(w)\n",
        "        curr_bins = {}\n",
        "        curr_bins[\"bin\"] = np.random.choice(np.arange(self.n_bins), p=p)\n",
        "\n",
        "        if choice_key==\"rescale\":\n",
        "          if uniform_bin_sampling:\n",
        "            p = np.ones(6)/6\n",
        "          else:\n",
        "            w = self.AUG_DICT[choice_key][\"weight\"][1]\n",
        "            p = self.weight_to_p(w)\n",
        "          curr_bins[\"bin2\"] = np.random.choice(np.arange(6), p=p)\n",
        "\n",
        "        aug_x = transformation(aug_x, **curr_bins)\n",
        "        bins.append(curr_bins)\n",
        "\n",
        "    return np.array(aug_x), choices, bins\n",
        "\n",
        "  def augment_batch(self, batch):\n",
        "    aug_batch = tf.identity(batch)\n",
        "\n",
        "    #aug_batch = tf.map_fn(aug_batch, self.augment)\n",
        "    batch_choices = []\n",
        "    batch_bins = []\n",
        "    \n",
        "    if batch.ndim == 3:\n",
        "      sample, choices, bins = self.augment(sample)\n",
        "      batch_choices.append(choices)\n",
        "      batch_bins.append(bins)\n",
        "    elif batch.ndim == 4:\n",
        "      for sample in aug_batch:\n",
        "        sample, choices, bins = self.augment(sample)\n",
        "        batch_choices.append(choices)\n",
        "        batch_bins.append(bins)\n",
        "\n",
        "    return aug_batch, batch_choices, batch_bins\n",
        "\n",
        "  def update_weights(self, label, pred, choices, bins):\n",
        "    omega = 1 - (1 / (2*self.n_classes)) * np.sum(tf.math.abs(label - pred))\n",
        "\n",
        "    for k, choice in enumerate(choices):\n",
        "      w = self.AUG_DICT[choice][\"weight\"][0]\n",
        "      bin = bins[k][\"bin\"]\n",
        "      self.AUG_DICT[choice][\"weight\"][0][bin] = self.decay * w[bin] + (1 - self.decay) * omega\n",
        "      # print(self.AUG_DICT[choice][\"weight\"][0])\n",
        "      if choices[k] == \"rescale\":\n",
        "        w = self.AUG_DICT[choice][\"weight\"][1]\n",
        "        bin = bins[k][\"bin2\"]\n",
        "        self.AUG_DICT[choice][\"weight\"][1][bin] = self.decay * w[bin] + (1 - self.decay) * omega\n",
        "\n",
        "\n",
        "\n",
        "  def update_weights_batch(self, labels, preds, choices, bins):\n",
        "    [self.update_weights(l, p, c, b) for l, p, c, b in zip(labels, preds, choices, bins)]\n",
        "\n",
        "  def get_param(self, r_min, r_max, bin):\n",
        "      possible_value = np.linspace(r_min, r_max, self.n_bins)\n",
        "      return possible_value[bin]\n",
        "\n",
        "  def autocontrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.autocontrast(x), param)\n",
        "  \n",
        "  def blur(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.BLUR), param)\n",
        "  \n",
        "  def brightness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Brightness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def color(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Color(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def contrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Contrast(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def cutout(self, x, bin):\n",
        "    \"\"\"Taken directlly from FixMatch code\"\"\"\n",
        "    level = self.get_param(0, 0.5, bin)\n",
        "\n",
        "    size = 1 + int(level * min(x.size) * 0.499)\n",
        "    img_height, img_width = x.size\n",
        "    height_loc = np.random.randint(low=0, high=img_height)\n",
        "    width_loc = np.random.randint(low=0, high=img_width)\n",
        "    upper_coord = (max(0, height_loc - size // 2), max(0, width_loc - size // 2))\n",
        "    lower_coord = (min(img_height, height_loc + size // 2), min(img_width, width_loc + size // 2))\n",
        "    pixels = x.load()  # create the pixel map\n",
        "    for i in range(upper_coord[0], lower_coord[0]):  # for every col:\n",
        "        for j in range(upper_coord[1], lower_coord[1]):  # For every row\n",
        "            pixels[i, j] = (127, 127, 127)  # set the color accordingly\n",
        "    return x\n",
        "\n",
        "  def equalize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.equalize(x), param)\n",
        "\n",
        "  def invert(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.invert(x), param)\n",
        "  \n",
        "  def identity(self, x, bin):\n",
        "      return x\n",
        "\n",
        "  def posterize(self, x, bin):\n",
        "      param = int(self.get_param(0, 8, bin))\n",
        "      return ImageOps.posterize(x, param)\n",
        "\n",
        "  def rescale(self, x, bin, bin2):\n",
        "      param = self.get_param(0.5, 1, bin)\n",
        "      methods = (Image.ANTIALIAS, Image.BICUBIC, Image.BILINEAR, Image.BOX, Image.HAMMING, Image.NEAREST)\n",
        "      method = methods[bin2]\n",
        "      s = x.size\n",
        "      scale = param*0.25\n",
        "      crop = (scale * s[0], scale * s[1], s[0] * (1 - scale), s[1] * (1 - scale))\n",
        "      return x.crop(crop).resize(x.size, method)\n",
        "\n",
        "  def rotate(self, x, bin):\n",
        "      param = self.get_param(-45, 45, bin)\n",
        "      angle = int(np.round((2 * param - 1) * 45))\n",
        "      return x.rotate(angle)\n",
        "\n",
        "  def sharpness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Sharpness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def shear_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, shear, 0, 0, 1, 0))\n",
        "\n",
        "  def shear_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, shear, 1, 0))\n",
        "\n",
        "  def smooth(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.SMOOTH), param)\n",
        "\n",
        "  def solarize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      th = int(param * 255.999)\n",
        "      return ImageOps.solarize(x, th)\n",
        "\n",
        "  def translate_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, delta, 0, 1, 0))\n",
        "\n",
        "  def translate_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, 0, 1, delta))\n",
        "\n",
        "\n",
        "class OurCosineDecay(tf.keras.experimental.CosineDecay):\n",
        "\n",
        "  def __call__(self, step):\n",
        "    with ops.name_scope_v2(self.name or \"CosineDecay\"):\n",
        "      initial_learning_rate = ops.convert_to_tensor_v2(\n",
        "          self.initial_learning_rate, name=\"initial_learning_rate\")\n",
        "      dtype = initial_learning_rate.dtype\n",
        "      decay_steps = math_ops.cast(self.decay_steps, dtype)\n",
        "\n",
        "      global_step_recomp = math_ops.cast(step, dtype)\n",
        "      global_step_recomp = math_ops.minimum(global_step_recomp, decay_steps)\n",
        "      completed_fraction = global_step_recomp / decay_steps\n",
        "      cosine_decayed = math_ops.cos(\n",
        "          constant_op.constant(7/16 * math.pi) * completed_fraction)\n",
        "\n",
        "      decayed = (1 - self.alpha) * cosine_decayed + self.alpha\n",
        "      return math_ops.multiply(initial_learning_rate, decayed)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MY99qVwV6hh"
      },
      "source": [
        "\n",
        "def training(model, ds_l, ds_u, hparams, n_classes, mean=None, std=None,\n",
        "                   val_interval=2000, log_interval=200, batch_size=128):\n",
        "\n",
        "    def train_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)#/255.\n",
        "        return x, y\n",
        "\n",
        "    def valid_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)#/255.\n",
        "        return x, y\n",
        "\n",
        "    def weak_transformation(x):\n",
        "      x = tf.image.random_flip_left_right(x)\n",
        "      max_shift = tf.cast(x.shape[1]*0.125, dtype=tf.dtypes.int32)\n",
        "      shift = tf.random.uniform([x.shape[0], 2], minval=-max_shift, maxval=max_shift, dtype=tf.dtypes.int32)\n",
        "      return tfa.image.translate(x, tf.cast(shift, tf.dtypes.float32))\n",
        "      \n",
        "\n",
        "    def pseudolabel(class_dist):\n",
        "        argmax = tf.math.argmax(class_dist, axis=1)\n",
        "        return tf.one_hot(argmax, class_dist.shape[1])\n",
        "\n",
        "    def threshold_gate(one_hot, logits, threshold):\n",
        "        max_probs = tf.math.multiply(one_hot, tf.nn.softmax(logits))\n",
        "        return tf.cast(max_probs > threshold, max_probs.dtype)# * max_probs\n",
        "\n",
        "    def split_data_into_arrays(ds):\n",
        "        images = []\n",
        "        labels = []\n",
        "        for ex in ds.take(50000000):\n",
        "            try:\n",
        "                images.append(ex[0])\n",
        "                labels.append(ex[1])\n",
        "            except:\n",
        "                break\n",
        "        return np.stack(images), np.stack(labels)\n",
        "\n",
        "    \n",
        "    #@tf.function\n",
        "    def step(x_l, y_l, x_u, n_classes, training):\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            if y_l.ndim is 1:\n",
        "              y_l = tf.one_hot(y_l, n_classes)            \n",
        "\n",
        "            # labeled data\n",
        "            x_l_weak = weak_transformation(x_l)\n",
        "            output_l = model(x_l_weak, training)\n",
        "            \n",
        "            loss_l = loss_fn(y_l, output_l)\n",
        "\n",
        "            \n",
        "            # unlabeled data\n",
        "            x_u_weak = weak_transformation(x_u)\n",
        "            output_u_weak = model(x_u_weak, training)  # should this be training or not?\n",
        "            y_u = pseudolabel(output_u_weak)\n",
        "            y_u = threshold_gate(y_u, output_u_weak, hparams['tau'])\n",
        "\n",
        "            x_u_strong, choices, bins = cta.augment_batch(x_u)\n",
        "            output_u_strong = model(x_u_strong, training)\n",
        "            cta.update_weights_batch(y_u, output_u_strong, choices, bins)\n",
        "          \n",
        "            loss_u = loss_fn(y_u, output_u_strong)\n",
        "\n",
        "            # tf.print(loss_u)   \n",
        "            # print(loss_u)   \n",
        "\n",
        "            #add losses together\n",
        "            loss = loss_l + hparams['lamda'] * loss_u\n",
        "\n",
        "        if training:\n",
        "            gradients = tape.gradient(loss, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        class_pred = tf.math.argmax(output_l, axis=1)\n",
        "        tmp = tf.argmax(y_l, axis=1)\n",
        "        #accuracy(tmp, class_pred)\n",
        "        labeled_loss(loss_l)\n",
        "        unlabeled_loss(loss_u)\n",
        "\n",
        "        labels = np.argmax(y_u, axis=1)\n",
        "        labels[np.sum(y_u, axis=1) == 0] = -1\n",
        "        return labels\n",
        "\n",
        "    schedule = OurCosineDecay(hparams['eta'], hparams['K'])\n",
        "    optimizer = tf.keras.optimizers.SGD(schedule, momentum=hparams['beta'], nesterov=hparams['nesterov'])\n",
        "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    cta = CTAugment(hparams['cta_classes'], hparams['cta_decay'], hparams['cta_threshold'], hparams['cta_depth'])\n",
        "\n",
        "    full_x_l, full_y_l = split_data_into_arrays(ds_l)\n",
        "    full_x_u, _ = split_data_into_arrays(ds_u)\n",
        "    \n",
        "    # split into batches\n",
        "    ds_l = ds_l.map(train_prep).batch(hparams['batch_size']).prefetch(-1)\n",
        "    ds_u = ds_u.map(train_prep).batch(hparams['batch_size']).prefetch(-1)\n",
        "\n",
        "\n",
        "    #runid = run_name + '_x' + str(np.random.randint(10000))\n",
        "    #writer = tf.summary.create_file_writer(logdir + '/' + runid)\n",
        "    accuracy = tf.metrics.SparseCategoricalAccuracy()\n",
        "    labeled_loss = tf.metrics.Mean()\n",
        "    unlabeled_loss = tf.metrics.Mean()\n",
        "    \n",
        "    #print(f\"RUNID: {runid}\")\n",
        "    #tf.keras.utils.plot_model(model)#, os.path.join('saved_plots', runid + '.png'))    \n",
        "\n",
        "    training_step = 0\n",
        "    best_validation_acc = 0\n",
        "    epochs = 5\n",
        "\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        y_u = np.array([])\n",
        "        for (x_l, y_l), (x_u, _) in tqdm(zip(ds_l, ds_u), desc=f'epoch {epoch+1}/{epochs}',\n",
        "                         total=val_interval, ncols=100, ascii=True):\n",
        "            tf.print(\"step\")\n",
        "\n",
        "            training_step += 1\n",
        "            y_batch = step(x_l, y_l, x_u, n_classes, training=True)\n",
        "            y_batch[1] = np.random.randint(0, 9)\n",
        "            y_u = np.concatenate((y_u, y_batch))\n",
        "            tf.print(y_batch)\n",
        "\n",
        "            #idx = np.where(np.count_nonzero(y_u) == n_classes)\n",
        "\n",
        "            #x_new_l = np.delete(x_u, idx, axis=0)\n",
        "            #y_new_l = np.delete(y_u, idx, axis=0)\n",
        "\n",
        "            #x_l = np.concatenate((x_l, x_new_l))\n",
        "            #y_l = np.concatenate((y_l, y_new_l))\n",
        "            \n",
        "            #tf.print(x_new_l)\n",
        "\n",
        "            if training_step % log_interval == 0:\n",
        "                #with writer.as_default():\n",
        "                    loss_l, loss_u, err = labeled_loss.result(), unlabeled_loss.result(), 1-accuracy.result()\n",
        "                    print(f\" loss_l: {loss_l:^6.3f} | loss_u: {loss_u:^6.3f} | err: {err:^6.3f}\", end='\\r')\n",
        "\n",
        "                    tf.summary.scalar('train/error_rate', err, training_step)\n",
        "                    tf.summary.scalar('train/labeled_loss', loss_l, training_step)\n",
        "                    tf.summary.scalar('train/unlabeled_loss', loss_u, training_step)\n",
        "                    tf.summary.scalar('train/learnig_rate', optimizer._decayed_lr('float32'), training_step)\n",
        "                    labeled_loss.reset_states()\n",
        "                    unlabeled_loss.reset_states()\n",
        "                    accuracy.reset_states()\n",
        "\n",
        "        # filter out and move pseudolabeled data from ds_u to ds_l\n",
        "        #newly_labeled = ds_u.filter(lambda x, y: 1)\n",
        "        #ds_u = ds_u.filter(lambda y: y if y is NOT a proper pseudolabel)\n",
        "        #ds_l = ds_l.concatenate(newly_labeled)\n",
        "\n",
        "        tf.print(full_x_u.shape, full_x_l.shape)\n",
        "        y_dim = y_u.shape[0]\n",
        "        tf.print(y_u.shape)\n",
        "        tf.print(\"number unlabeled samlples {}\".format(y_dim))\n",
        "       \n",
        "        tf.print(full_x_u.shape)\n",
        "        new_x_l = [full_x_u[i, :, :, :] for i in range(y_dim) if y_u[i] > -1]\n",
        "        new_y_l = [y_u[i] for i in range(y_dim) if y_u[i] > -1]\n",
        "\n",
        "        if len(new_x_l) > 0:\n",
        "          new_x_l = np.stack(new_x_l)\n",
        "          new_y_l = np.stack(new_y_l)\n",
        "          \n",
        "          new_x_u = [full_x_u[i, :, :, :] for i in range(y_dim) if y_u[i] == -1]\n",
        "          full_x_u = new_x_u\n",
        "\n",
        "          if len(full_x_u) > 0:\n",
        "            full_x_u = np.stack(full_x_u)\n",
        "        \n",
        "          full_x_l = np.concatenate((full_x_l, new_x_l))\n",
        "          full_y_l = np.concatenate((full_y_l, new_y_l))\n",
        "\n",
        "\n",
        "        labeled_loss.reset_states()\n",
        "        unlabeled_loss.reset_states()\n",
        "        accuracy.reset_states()\n",
        "            "
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8wdZaaZ25bY"
      },
      "source": [
        "\n",
        "# hyperparams\n",
        "lamda = 1     # proportion of unlabeled loss in total loss\n",
        "eta = 0.03    # learning rate\n",
        "beta = 0.09   # momentum\n",
        "tau = 0.95    # threshold in pseudo-labeling\n",
        "mu = 0.7      # proportion of unlabeled samples in batch\n",
        "B = 64        # number of labeled examples in batch(in training)\n",
        "K = 2 ** 20\n",
        "nesterov = False\n",
        "batch_size = 2  # should be 64?\n",
        "# weight decay\n",
        "# SGD instead of Adam\n",
        "\n",
        "\n",
        "#CTAugment params\n",
        "cta_classes = 10\n",
        "cta_decay = 0.99\n",
        "cta_depth = 2\n",
        "cta_threshold = 0.8\n",
        "\n",
        "hparams = {'lamda': lamda, 'eta': eta, 'beta': beta, 'tau': tau, 'mu': mu, 'B': B, 'K': K, 'nesterov': False, 'batch_size': batch_size,\n",
        "           'cta_classes': cta_classes, 'cta_decay': cta_decay, 'cta_depth': cta_depth, 'cta_threshold': cta_threshold}\n",
        "\n",
        "n_classes = 10"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9vH0aDt5Ry"
      },
      "source": [
        "model = WRN_28_2()\n"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tNCCUFNSlOP"
      },
      "source": [
        "def ParseFunction(serialized, image_shape=[32, 32, 3]):\n",
        "    features = {'image': tf.io.FixedLenFeature([], tf.string),\n",
        "                'label': tf.io.FixedLenFeature([], tf.int64)}\n",
        "\n",
        "    parsed_example = tf.io.parse_single_example(serialized=serialized, features=features) \n",
        "    image = tf.image.decode_image(parsed_example['image'])\n",
        "    image.set_shape(image_shape)\n",
        "    # image = tf.cast(image, tf.float32) * (2.0 / 255) - 1.0\n",
        "    data = dict(image=image, label=parsed_example['label'])\n",
        "    return data\n",
        "\n",
        "def stl_ParseFunction(input):\n",
        "  return ParseFunction(serialized=input, image_shape=[96, 96, 3])\n",
        "\n",
        "def LoadData(filename, tensor=False):\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "  dataset = dataset.map(ParseFunction)\n",
        "  \n",
        "  # it = tf.compat.v1.data.make_one_shot_iterator(dataset) # Never used?\n",
        "  images = np.stack([x['image'] for x in dataset])\n",
        "  labels = np.stack([x['label'] for x in dataset])\n",
        "\n",
        "  if tensor:\n",
        "      return tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "  else:\n",
        "      return images, labels\n",
        "\n",
        "  def split_data_into_arrays(ds):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for ex in ds.take(50000000):\n",
        "      try:\n",
        "        images.append(ex[0])\n",
        "        labels.append(ex[1])\n",
        "      except:\n",
        "        break\n",
        "    return np.stack(images), np.stack(labels)\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bkYlQ3BbM5A"
      },
      "source": [
        "fpath = '/content/drive/My Drive/Colab Notebooks/cifar10.3@10-label.tfrecord'\n",
        "\n",
        "ds_l = LoadData(fpath, tensor=True)\n",
        "\n",
        "ds_u = LoadData(fpath, tensor=True)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsDerohJ4RAw",
        "outputId": "b734afa5-3c18-4dc1-8f76-36fa265502fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "training(model, ds_l, ds_u, hparams, n_classes)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\repoch 1/5:   0%|                                                           | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 1/5:   0%|                                                   | 1/2000 [00:00<12:41,  2.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  6])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 1/5:   0%|                                                   | 2/2000 [00:00<10:39,  3.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 1/5:   0%|                                                   | 3/2000 [00:00<09:07,  3.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 1/5:   0%|1                                                  | 4/2000 [00:00<07:57,  4.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  4])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1/5:   0%|1                                                  | 5/2000 [00:01<07:00,  4.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(10, 32, 32, 3) (10, 32, 32, 3)\n",
            "(10,)\n",
            "number unlabeled samlples 10\n",
            "(10, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\repoch 2/5:   0%|                                                           | 0/2000 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 2/5:   0%|                                                   | 1/2000 [00:00<05:39,  5.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  8])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 2/5:   0%|                                                   | 2/2000 [00:00<05:35,  5.95it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 2/5:   0%|                                                   | 3/2000 [00:00<05:38,  5.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  2])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\repoch 2/5:   0%|1                                                  | 4/2000 [00:00<05:31,  6.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step\n",
            "array([-1,  3])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2/5:   0%|1                                                  | 5/2000 [00:00<05:31,  6.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(5, 32, 32, 3) (15, 32, 32, 3)\n",
            "(10,)\n",
            "number unlabeled samlples 10\n",
            "(5, 32, 32, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-141-dad6cc17ec23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-136-cbe719670a14>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, ds_l, ds_u, hparams, n_classes, mean, std, val_interval, log_interval, batch_size)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_x_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mnew_x_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfull_x_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mnew_y_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-136-cbe719670a14>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_x_u\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0mnew_x_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfull_x_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0mnew_y_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0my_u\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O71Qt-X7sfa"
      },
      "source": [
        "def test_error(model, test_data, test_labels):\n",
        "  out = model(test_data)\n",
        "  out_l = tf.math.argmax(out, axis=1)\n",
        "  return np.sum(out_l == test_labels)/len(test_labels)\n",
        "\n",
        "test_error(model, im, ls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQDq8TrkQ72F",
        "outputId": "25c12f70-4592-4498-9214-c607433d097e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "\n",
        "    "
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-5d9680ba81e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_l\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_l\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'TensorSliceDataset' object does not support indexing"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ET93aSebHs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctr7_6KvamqI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_P-BZbCa0HS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfACBOMva4_E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCVeRzVwbFam"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNlFiu2Rzf5C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JAbVTvztHEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCLINL2XWLhR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1xOtqKpuLZ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}