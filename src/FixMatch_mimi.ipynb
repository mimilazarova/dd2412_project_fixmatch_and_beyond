{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FixMatch_mimi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimilazarova/dd2412_project_fixmatch_and_beyond/blob/main/src/FixMatch_mimi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmfb90N9fjlY",
        "outputId": "7aee16ba-13f3-47a5-f0b7-0fe0db1d889c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pip install tensorflow-addons==0.11.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons==0.11.1 in /usr/local/lib/python3.6/dist-packages (0.11.1)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.11.1) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IEcnAYIWS4Q"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXaHCn3SUuY7"
      },
      "source": [
        "\n",
        "def regularized_padded_conv(*args, **kwargs):\n",
        "    return tf.keras.layers.Conv2D(*args, **kwargs, padding='same', kernel_regularizer=_regularizer,\n",
        "                                  kernel_initializer='he_normal', use_bias=False)\n",
        "\n",
        "\n",
        "def BN_ReLU(x):\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    return tf.keras.layers.ReLU()(x)\n",
        "\n",
        "\n",
        "def shortcut(x, filters, stride, mode):\n",
        "    if x.shape[-1] == filters:\n",
        "        return x\n",
        "    elif mode == 'B':\n",
        "        return regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "    elif mode == 'B_original':\n",
        "        x = regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "        return tf.keras.layers.BatchNormalization()(x)\n",
        "    elif mode == 'A':\n",
        "        return tf.pad(tf.keras.layers.MaxPool2D(1, stride)(x) if stride>1 else x,\n",
        "                      paddings=[(0, 0), (0, 0), (0, 0), (0, filters - x.shape[-1])])\n",
        "    else:\n",
        "        raise KeyError(\"Parameter shortcut_type not recognized!\")\n",
        "    \n",
        "\n",
        "def original_block(x, filters, stride=1, **kwargs):\n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(x)\n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "    \n",
        "    mode = 'B_original' if _shortcut_type == 'B' else _shortcut_type\n",
        "    x = shortcut(x, filters, stride, mode=mode)\n",
        "    return tf.keras.layers.ReLU()(x + c2)\n",
        "    \n",
        "    \n",
        "def preactivation_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "        \n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(flow)\n",
        "    if _dropout:\n",
        "        c1 = tf.keras.layers.Dropout(_dropout)(c1)\n",
        "        \n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c2\n",
        "\n",
        "\n",
        "def bootleneck_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "         \n",
        "    c1 = regularized_padded_conv(filters//_bootleneck_width, 1)(flow)\n",
        "    c2 = regularized_padded_conv(filters//_bootleneck_width, 3, strides=stride)(BN_ReLU(c1))\n",
        "    c3 = regularized_padded_conv(filters, 1)(BN_ReLU(c2))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c3\n",
        "\n",
        "\n",
        "def group_of_blocks(x, block_type, num_blocks, filters, stride, block_idx=0):\n",
        "    global _preact_shortcuts\n",
        "    preact_block = True if _preact_shortcuts or block_idx == 0 else False\n",
        "    \n",
        "    x = block_type(x, filters, stride, preact_block=preact_block)\n",
        "    for i in range(num_blocks-1):\n",
        "        x = block_type(x, filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Resnet(input_shape, n_classes, l2_reg=1e-4, group_sizes=(2, 2, 2), features=(16, 32, 64), strides=(1, 2, 2),\n",
        "           shortcut_type='B', block_type='preactivated', first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1},\n",
        "           dropout=0, cardinality=1, bootleneck_width=4, preact_shortcuts=True):\n",
        "    \n",
        "    global _regularizer, _shortcut_type, _preact_projection, _dropout, _cardinality, _bootleneck_width, _preact_shortcuts\n",
        "    _bootleneck_width = bootleneck_width # used in ResNeXts and bootleneck blocks\n",
        "    _regularizer = tf.keras.regularizers.l2(l2_reg)\n",
        "    _shortcut_type = shortcut_type # used in blocks\n",
        "    _cardinality = cardinality # used in ResNeXts\n",
        "    _dropout = dropout # used in Wide ResNets\n",
        "    _preact_shortcuts = preact_shortcuts\n",
        "    \n",
        "    block_types = {'preactivated': preactivation_block,\n",
        "                   'bootleneck': bootleneck_block,\n",
        "                   'original': original_block}\n",
        "    \n",
        "    selected_block = block_types[block_type]\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    flow = regularized_padded_conv(**first_conv)(inputs)\n",
        "    \n",
        "    if block_type == 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    for block_idx, (group_size, feature, stride) in enumerate(zip(group_sizes, features, strides)):\n",
        "        flow = group_of_blocks(flow,\n",
        "                               block_type=selected_block,\n",
        "                               num_blocks=group_size,\n",
        "                               block_idx=block_idx,\n",
        "                               filters=feature,\n",
        "                               stride=stride)\n",
        "    \n",
        "    if block_type != 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    flow = tf.keras.layers.GlobalAveragePooling2D()(flow)\n",
        "    outputs = tf.keras.layers.Dense(n_classes, kernel_regularizer=_regularizer)(flow)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_weights_func(model, model_name):\n",
        "    try: model.load_weights(os.path.join('saved_models', model_name + '.tf'))\n",
        "    except tf.errors.NotFoundError: print(\"No weights found for this model!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def cifar_wide_resnet(N, K, block_type='preactivated', shortcut_type='B', dropout=0, l2_reg=2.5e-4):\n",
        "    assert (N-4) % 6 == 0, \"N-4 has to be divisible by 6\"\n",
        "    lpb = (N-4) // 6 # layers per block - since N is total number of convolutional layers in Wide ResNet\n",
        "    model = Resnet(input_shape=(32, 32, 3), n_classes=10, l2_reg=l2_reg, group_sizes=(lpb, lpb, lpb), features=(16*K, 32*K, 64*K),\n",
        "                   strides=(1, 2, 2), first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1}, shortcut_type=shortcut_type,\n",
        "                   block_type=block_type, dropout=dropout, preact_shortcuts=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def WRN_28_2(shortcut_type='B', load_weights=False, dropout=0, l2_reg=2.5e-4):\n",
        "    model = cifar_wide_resnet(28, 2, 'preactivated', shortcut_type, dropout=dropout, l2_reg=l2_reg)\n",
        "    if load_weights: model = load_weights_func(model, 'cifar_WRN_28_10')\n",
        "    return model\n",
        "\n",
        "\n",
        "def FixMatch():\n",
        "  self.resnet = WRN_28_2()\n",
        "\n",
        "  \"\"\"\n",
        "  Unlabeled data\n",
        "  weak_input = weak_transformation(input)\n",
        "  strong_input = strong_transformation(input)\n",
        "\n",
        "  weak_output = resnet(weak_input)\n",
        "  strong_output = resnet(strong_input)\n",
        "  \n",
        "  pseudo_label = pseudolabel(weak_output)\n",
        "  cross_ent = crossentropy(pseudo_label, strong_output)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hfy2W4iGscd"
      },
      "source": [
        "class CTAugment:\n",
        "\n",
        "  def __init__(self, decay=0.99, threshold=0.85, n_xform=2, n_bins=17):\n",
        "    self.decay = decay\n",
        "    self.threshold = threshold\n",
        "    self.n_xform = n_xform\n",
        "    self.n_bins = n_bins\n",
        "  \n",
        "    # we need some way of storing functions so that we can randomly sample\n",
        "    # from them. The format below might not be perfect but it is nice if we \n",
        "    # can generate a index i wish with which we can access the ith\n",
        "    # transformation, its corresponding bins and their weights\n",
        "    self.xforms = []\n",
        "    self.bins = [[]]\n",
        "    self.weights = [[]]\n",
        "\n",
        "    self.AUG_DICT = {\n",
        "        \"autocontrast\": {\"f\": self.autocontrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"blur\": {\"f\": self.blur, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"brightness\": {\"f\": self.brightness, \"weight\":[np.ones(self.n_bins)*1.0]},\n",
        "        \"color\": {\"f\": self.color, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"contrast\": {\"f\": self.contrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"cutout\": {\"f\": self.cutout, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"equalize\": {\"f\": self.equalize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"invert\": {\"f\": self.invert, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"identity\": {\"f\": self.identity, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"posterize\": {\"f\": self.posterize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"rescale\": {\"f\": self.rescale, \"weight\": [np.ones(self.n_bins)*1.0, np.ones(6)*1.0]},\n",
        "        \"rotate\": {\"f\": self.rotate, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"sharpness\": {\"f\": self.sharpness, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_x\": {\"f\": self.shear_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_y\": {\"f\": self.shear_y, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"smooth\": {\"f\": self.smooth, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"solarize\": {\"f\": self.solarize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_x\": {\"f\": self.translate_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_y\": {\"f\": self.translate_y, \"weight\": [np.ones(self.n_bins)*1.0]}\n",
        "    }\n",
        "    self.N = len(self.AUG_DICT.keys())\n",
        "    self.options = list(self.AUG_DICT.keys())\n",
        "\n",
        "  def weight_to_p(self, weight):\n",
        "        p = weight + (1 - self.decay)  # Avoid to have all zero.\n",
        "        p = p / p.max()\n",
        "        p[p < self.threshold] = 0\n",
        "        return p/np.sum(p)\n",
        "\n",
        "\n",
        "  def augment(self, x):\n",
        "    choices = [self.options[i] for i in np.random.choice(np.arange(self.N), self.n_xform, replace=False)]\n",
        "    \n",
        "    aug_x = Image.fromarray(np.uint8(x))\n",
        "\n",
        "    for k in range(self.n_xform):\n",
        "        # i = tf.random.uniform() # we generate a function randomly\n",
        "        choice_key = choices[k]\n",
        "        \n",
        "        transformation = self.AUG_DICT[choice_key][\"f\"]\n",
        "        # pick weights for correpsonding function and set weigths to 0 if they \n",
        "        # are less than 0.8\n",
        "        w = self.AUG_DICT[choice_key][\"weight\"][0]\n",
        "        # print(choice_key)\n",
        "        p = self.weight_to_p(w)\n",
        "        bins = {}\n",
        "        bins[\"bin\"] = np.random.choice(np.arange(self.n_bins), p=p)\n",
        "\n",
        "        if choice_key==\"rescale\":\n",
        "          w = self.AUG_DICT[choice_key][\"weight\"][1]\n",
        "          p = self.weight_to_p(w)\n",
        "          bins[\"bin2\"] = np.random.choice(np.arange(6), p=p)\n",
        "\n",
        "        # we should probably copy here so we do not overwrite original\n",
        "        aug_x = transformation(aug_x, **bins)\n",
        "      \n",
        "    return np.array(aug_x)\n",
        "\n",
        "  def update_weights(self, parameter, weights):\n",
        "      pass\n",
        "\n",
        "  def get_param(self, r_min, r_max, bin):\n",
        "      possible_value = np.linspace(r_min, r_max, self.n_bins)\n",
        "      return possible_value[bin]\n",
        "\n",
        "  def autocontrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.autocontrast(x), param)\n",
        "  \n",
        "  def blur(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.BLUR), param)\n",
        "  \n",
        "  def brightness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Brightness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def color(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Color(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def contrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Contrast(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def cutout(self, x, bin):\n",
        "    \"\"\"Taken directlly from FixMatch code\"\"\"\n",
        "    level = self.get_param(0, 0.5, bin)\n",
        "\n",
        "    size = 1 + int(level * min(x.size) * 0.499)\n",
        "    img_height, img_width = x.size\n",
        "    height_loc = np.random.randint(low=0, high=img_height)\n",
        "    width_loc = np.random.randint(low=0, high=img_width)\n",
        "    upper_coord = (max(0, height_loc - size // 2), max(0, width_loc - size // 2))\n",
        "    lower_coord = (min(img_height, height_loc + size // 2), min(img_width, width_loc + size // 2))\n",
        "    pixels = x.load()  # create the pixel map\n",
        "    for i in range(upper_coord[0], lower_coord[0]):  # for every col:\n",
        "        for j in range(upper_coord[1], lower_coord[1]):  # For every row\n",
        "            pixels[i, j] = (127, 127, 127)  # set the color accordingly\n",
        "    return x\n",
        "\n",
        "  def equalize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.equalize(x), param)\n",
        "\n",
        "  def invert(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.invert(x), param)\n",
        "  \n",
        "  def identity(self, x, bin):\n",
        "      return x\n",
        "\n",
        "  def posterize(self, x, bin):\n",
        "      param = int(self.get_param(0, 8, bin))\n",
        "      return ImageOps.posterize(x, param)\n",
        "\n",
        "  def rescale(self, x, bin, bin2):\n",
        "      param = self.get_param(0.5, 1, bin)\n",
        "      methods = (Image.ANTIALIAS, Image.BICUBIC, Image.BILINEAR, Image.BOX, Image.HAMMING, Image.NEAREST)\n",
        "      method = methods[bin2]\n",
        "      s = x.size\n",
        "      scale = param*0.25\n",
        "      crop = (scale * s[0], scale * s[1], s[0] * (1 - scale), s[1] * (1 - scale))\n",
        "      return x.crop(crop).resize(x.size, method)\n",
        "\n",
        "  def rotate(self, x, bin):\n",
        "      param = self.get_param(-45, 45, bin)\n",
        "      angle = int(np.round((2 * param - 1) * 45))\n",
        "      return x.rotate(angle)\n",
        "\n",
        "  def sharpness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Sharpness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def shear_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, shear, 0, 0, 1, 0))\n",
        "\n",
        "  def shear_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, shear, 1, 0))\n",
        "\n",
        "  def smooth(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.SMOOTH), param)\n",
        "\n",
        "  def solarize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      th = int(param * 255.999)\n",
        "      return ImageOps.solarize(x, th)\n",
        "\n",
        "  def translate_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, delta, 0, 1, 0))\n",
        "\n",
        "  def translate_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, 0, 1, delta))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuOsM6UKXp17",
        "outputId": "18cf7df9-2d20-4fe1-cbe6-213cc75bb7e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ds = tfds.load('cifar10', split=\"train\")\n",
        "ds"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<DatasetV1Adapter shapes: {image: (32, 32, 3), label: ()}, types: {image: tf.uint8, label: tf.int64}>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RESn9DuEYUR8",
        "outputId": "7d79f26e-2de5-48dc-bae1-9d9822bb1d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "for example in ds.take(5):\n",
        "  image, label = example[\"image\"], example[\"label\"]\n",
        "\n",
        "print(np.max(image))\n",
        "\n",
        "plt.imshow(image)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "209\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6f91839630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Grmk-DcUF7",
        "outputId": "aa6696ba-b3ac-4729-8380-63e624f34df4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "cta = CTAugment()\n",
        "new = cta.augment(image)\n",
        "plt.imshow(new)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6f917d7860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MY99qVwV6hh"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "\n",
        "def training(model, ds, mean=None, std=None, lr_values=[0.01, 0.1, 0.01, 0.001], lr_boundaries=[400, 32000, 48000, 64000],\n",
        "                   val_interval=2000, log_interval=200, batch_size=128, nesterov=False):\n",
        "\n",
        "    schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=lr_boundaries[:-1], values=lr_values)\n",
        "    optimizer = tf.keras.optimizers.SGD(schedule, momentum=0.9, nesterov=nesterov)\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    \n",
        "    def train_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        #x = tf.image.random_flip_left_right(x)\n",
        "        #x = tf.image.pad_to_bounding_box(x, 4, 4, 40, 40) #must fix ds independent shape\n",
        "        #x = tf.image.random_crop(x, (32, 32, 3))          #must fix ds independent shape\n",
        "        if mean is not None and std is not None:\n",
        "          x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "    def valid_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        if mean is not None and std is not None:\n",
        "          x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "    #ds['train'] = ds['train'].map(train_prep).shuffle(10000).repeat().batch(batch_size).prefetch(-1)\n",
        "    ds['train'] = ds['train'].map(train_prep).batch(batch_size).prefetch(-1)\n",
        "    ds['test'] = ds['test'].map(valid_prep).batch(batch_size*4).prefetch(-1)\n",
        "\n",
        "    #runid = run_name + '_x' + str(np.random.randint(10000))\n",
        "    #writer = tf.summary.create_file_writer(logdir + '/' + runid)\n",
        "    accuracy = tf.metrics.SparseCategoricalAccuracy()\n",
        "    cls_loss = tf.metrics.Mean()\n",
        "    reg_loss = tf.metrics.Mean()\n",
        "    \n",
        "    #print(f\"RUNID: {runid}\")\n",
        "    #tf.keras.utils.plot_model(model)#, os.path.join('saved_plots', runid + '.png'))\n",
        "\n",
        "    def weak_transformation(x):\n",
        "      x = tf.image.random_flip_left_right(x)\n",
        "      max_shift = tf.cast(x.shape[1]*0.125, dtype=tf.dtypes.int32)\n",
        "      shift = tf.random.uniform([x.shape[0], 2], minval=-max_shift, maxval=max_shift, dtype=tf.dtypes.int32)\n",
        "      return tfa.image.translate(x, tf.cast(shift, tf.dtypes.float32))\n",
        "\n",
        "    def strong_transformation(x):\n",
        "      parameter_a = {'bins': [],\n",
        "                     'weights': [1, 1, 1]}\n",
        "\n",
        "      wegihts = [weight if weight > 0.8 else 0 for weight in parameter_a['weights']]\n",
        "      # weights = normalize(weights)\n",
        "      # logit_weights = logits(weights)\n",
        "      tf.random.categorical(logits, num_samples, dtype=None, seed=None, name=None)\n",
        "      pass\n",
        "\n",
        "    def pseudolabel(class_dist):\n",
        "        argmax = tf.math.argmax(class_dist, axis=1)\n",
        "        return tf.one_hot(argmax, class_dist.shape[1])\n",
        "\n",
        "    def threshold_gate(one_hot, logits, threshold):\n",
        "        max_probs = tf.math.multiply(one_hot, tf.nn.softmax(logits))\n",
        "        return tf.cast(max_probs > threshold, max_probs.dtype)# * max_probs\n",
        "\n",
        "    \n",
        "    @tf.function\n",
        "    def step(x, y, training):\n",
        "        with tf.GradientTape() as tape:\n",
        "            # unlabeled data\n",
        "            x_wk = weak_transformation(x)\n",
        "            outs_wk = model(x_wk, training)  # should this be training or not?\n",
        "            weak_labels = pseudolabel(outs_wk)\n",
        "            weak_labels = threshold_gate(weak_labels, outs_wk, 0.7)\n",
        "            #tf.print(weak_labels, summarize=10)\n",
        "\n",
        "            #x_str = strong_transformation(x)\n",
        "            #outs_str = model(x_str, training) #should this be training or not?\n",
        "            \n",
        "            #unlabeled_loss = loss_fn(weak_labels, outs_str)\n",
        "            \n",
        "            # labeled data\n",
        "            #outs = model(x, training)\n",
        "            #labeled_loss = loss_fn(y, outs)\n",
        "\n",
        "            #add losses together\n",
        "            #loss = labeled_loss + lambda * unlabeled_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            r_loss = tf.add_n(model.losses)\n",
        "            outs = model(x, training)\n",
        "            c_loss = loss_fn(y, outs)\n",
        "            loss = c_loss + r_loss\n",
        "\n",
        "        if training:\n",
        "            gradients = tape.gradient(loss, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        accuracy(y, outs)\n",
        "        cls_loss(c_loss)\n",
        "        reg_loss(r_loss)\n",
        "        \n",
        "\n",
        "    training_step = 0\n",
        "    best_validation_acc = 0\n",
        "    epochs = lr_boundaries[-1] // val_interval\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for x, y in tqdm(ds['train'].take(val_interval), desc=f'epoch {epoch+1}/{epochs}',\n",
        "                         total=val_interval, ncols=100, ascii=True):\n",
        "\n",
        "            training_step += 1\n",
        "            step(x, y, training=True)\n",
        "\n",
        "            if training_step % log_interval == 0:\n",
        "                #with writer.as_default():\n",
        "                    c_loss, r_loss, err = cls_loss.result(), reg_loss.result(), 1-accuracy.result()\n",
        "                    print(f\" c_loss: {c_loss:^6.3f} | r_loss: {r_loss:^6.3f} | err: {err:^6.3f}\", end='\\r')\n",
        "\n",
        "                    tf.summary.scalar('train/error_rate', err, training_step)\n",
        "                    tf.summary.scalar('train/classification_loss', c_loss, training_step)\n",
        "                    tf.summary.scalar('train/regularization_loss', r_loss, training_step)\n",
        "                    tf.summary.scalar('train/learnig_rate', optimizer._decayed_lr('float32'), training_step)\n",
        "                    cls_loss.reset_states()\n",
        "                    reg_loss.reset_states()\n",
        "                    accuracy.reset_states()\n",
        "\n",
        "        for x, y in ds['test']:\n",
        "            step(x, y, training=False)\n",
        "\n",
        "        #with writer.as_default(): TBULATE THE FOLLOWING WHEN UNCOMMENTING!\n",
        "        tf.summary.scalar('test/classification_loss', cls_loss.result(), step=training_step)\n",
        "        tf.summary.scalar('test/error_rate', 1-accuracy.result(), step=training_step)\n",
        "            \n",
        "        if accuracy.result() > best_validation_acc:\n",
        "                best_validation_acc = accuracy.result()\n",
        "                #model.save_weights(os.path.join('saved_models', runid + '.tf'))\n",
        "                \n",
        "        cls_loss.reset_states()\n",
        "        accuracy.reset_states()\n",
        "            \n",
        "    \n",
        "    \n",
        "def cifar_error_test(model, tr_len=20, vd_len=2):\n",
        "\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.SGD(0.01)\n",
        "\n",
        "    ds = tfds.load('cifar10', as_supervised=True, in_memory=True)\n",
        "    std = tf.reshape((0.2023, 0.1994, 0.2010), shape=(1, 1, 3))\n",
        "    mean= tf.reshape((0.4914, 0.4822, 0.4465), shape=(1, 1, 3))\n",
        "    \n",
        "    def train_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        x = tf.image.random_flip_left_right(x)\n",
        "        x = tf.image.pad_to_bounding_box(x, 4, 4, 40, 40)\n",
        "        x = tf.image.random_crop(x, (32, 32, 3))\n",
        "        x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "    def valid_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "    ds['train'] = ds['train'].map(train_prep).batch(5).take(tr_len).prefetch(-1)\n",
        "    ds['test'] = ds['test'].map(valid_prep).batch(5).take(vd_len).prefetch(-1)\n",
        "\n",
        "    accuracy = tf.metrics.SparseCategoricalAccuracy()\n",
        "    cls_loss = tf.metrics.Mean()\n",
        "    reg_loss = tf.metrics.Mean()\n",
        "\n",
        "    @tf.function\n",
        "    def step(x, y, training):\n",
        "        with tf.GradientTape() as tape:\n",
        "            r_loss = tf.add_n(model.losses)\n",
        "            outs = model(x, training)\n",
        "            c_loss = loss_fn(y, outs)\n",
        "            loss = c_loss + r_loss\n",
        "\n",
        "        if training:\n",
        "            gradients = tape.gradient(loss, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        accuracy(y, outs)\n",
        "        cls_loss(c_loss)\n",
        "        reg_loss(r_loss)\n",
        "        \n",
        "    training_step = 0\n",
        "    for x, y in tqdm(ds['train'], desc=f'test', total=tr_len, ncols=100, ascii=True):\n",
        "\n",
        "        training_step += 1\n",
        "        step(x, y, training=True)\n",
        "        c_loss, r_loss, err = cls_loss.result(), reg_loss.result(), 1-accuracy.result()\n",
        "        print(f\" c_loss: {c_loss:^6.3f} | r_loss: {r_loss:^6.3f} | err: {err:^6.3f}\", end='\\r')\n",
        "\n",
        "    for x, y in ds['test']:\n",
        "        step(x, y, training=False)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9vH0aDt5Ry",
        "outputId": "bff8d804-33b9-4325-e0e3-31fcc9e20c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "ds = tfds.load('cifar10', as_supervised=True, in_memory=True)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:`in_memory` if deprecated and will be removed in a future version. Please use `ds = ds.cache()` instead.\n",
            "WARNING:absl:`in_memory` if deprecated and will be removed in a future version. Please use `ds = ds.cache()` instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06AqVwlXATf"
      },
      "source": [
        "model = WRN_28_2()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIpVOZA3V7Wl",
        "outputId": "32d2ea76-b8d8-4e13-a025-405948a2611f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "training(model, ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 1/32:  10%|####8                                           | 201/2000 [00:47<05:00,  5.98it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " c_loss: 1.754  | r_loss: 1.015  | err: 0.649 \r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1/32:  16%|#######7                                        | 323/2000 [01:09<05:04,  5.50it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bkYlQ3BbM5A"
      },
      "source": [
        "#ds = tfds.load('cifar10', as_supervised=True, in_memory=True)\n",
        "\n",
        "mean = {\n",
        "'cifar10': tf.reshape((0.4914, 0.4822, 0.4465), shape=(1, 1, 3)),\n",
        "'cifar100': tf.reshape((0.5071, 0.4867, 0.4408), shape=(1, 1, 3)),\n",
        "}\n",
        "\n",
        "std = {\n",
        "'cifar10': tf.reshape((0.2023, 0.1994, 0.2010), shape=(1, 1, 3)),\n",
        "'cifar100': tf.reshape((0.2675, 0.2565, 0.2761), shape=(1, 1, 3))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ET93aSebHs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}