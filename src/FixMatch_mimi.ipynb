{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FixMatch_mimi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mimilazarova/dd2412_project_fixmatch_and_beyond/blob/main/src/FixMatch_mimi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwu53CIVxCUk",
        "outputId": "3154a103-b56c-485e-b7a7-944586a40b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmfb90N9fjlY",
        "outputId": "3f0ca650-c9eb-4564-9249-d8de1627e2ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "pip install tensorflow-addons==0.11.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/51/8e5bb7649ac136292aefef6ea0172d10cc23a26dcda093c62637585bc05e/tensorflow_addons-0.11.1-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 20.2MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 13.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 8.2MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 8.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 399kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 409kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 430kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 440kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 460kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 471kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 491kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 501kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 512kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 522kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 532kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 542kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 563kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 573kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 583kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 593kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 604kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 614kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 624kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 634kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 645kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 665kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 675kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 686kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 696kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 706kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 716kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 727kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 737kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 747kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 768kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 778kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 788kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 798kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 808kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 819kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 829kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 839kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 849kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 860kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 870kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 880kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 890kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 901kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 911kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 921kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 942kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 952kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 962kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 972kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 983kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 993kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.0MB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.11.1) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "  Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "Successfully installed tensorflow-addons-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrK1j-cwMj3Z"
      },
      "source": [
        "# All imports here\n",
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "from matplotlib import pyplot as plt\n",
        "import json"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXaHCn3SUuY7"
      },
      "source": [
        "# this cell is for the wide ResNet\n",
        "def regularized_padded_conv(*args, **kwargs):\n",
        "    return tf.keras.layers.Conv2D(*args, **kwargs, padding='same', kernel_regularizer=_regularizer,\n",
        "                                  kernel_initializer='he_normal', use_bias=False)\n",
        "\n",
        "\n",
        "def BN_ReLU(x):\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    return tf.keras.layers.ReLU()(x)\n",
        "\n",
        "\n",
        "def shortcut(x, filters, stride, mode):\n",
        "    if x.shape[-1] == filters:\n",
        "        return x\n",
        "    elif mode == 'B':\n",
        "        return regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "    elif mode == 'B_original':\n",
        "        x = regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "        return tf.keras.layers.BatchNormalization()(x)\n",
        "    elif mode == 'A':\n",
        "        return tf.pad(tf.keras.layers.MaxPool2D(1, stride)(x) if stride>1 else x,\n",
        "                      paddings=[(0, 0), (0, 0), (0, 0), (0, filters - x.shape[-1])])\n",
        "    else:\n",
        "        raise KeyError(\"Parameter shortcut_type not recognized!\")\n",
        "    \n",
        "\n",
        "def original_block(x, filters, stride=1, **kwargs):\n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(x)\n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "    \n",
        "    mode = 'B_original' if _shortcut_type == 'B' else _shortcut_type\n",
        "    x = shortcut(x, filters, stride, mode=mode)\n",
        "    return tf.keras.layers.ReLU()(x + c2)\n",
        "    \n",
        "    \n",
        "def preactivation_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "        \n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(flow)\n",
        "    if _dropout:\n",
        "        c1 = tf.keras.layers.Dropout(_dropout)(c1)\n",
        "        \n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c2\n",
        "\n",
        "\n",
        "def bootleneck_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "         \n",
        "    c1 = regularized_padded_conv(filters//_bootleneck_width, 1)(flow)\n",
        "    c2 = regularized_padded_conv(filters//_bootleneck_width, 3, strides=stride)(BN_ReLU(c1))\n",
        "    c3 = regularized_padded_conv(filters, 1)(BN_ReLU(c2))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c3\n",
        "\n",
        "\n",
        "def group_of_blocks(x, block_type, num_blocks, filters, stride, block_idx=0):\n",
        "    global _preact_shortcuts\n",
        "    preact_block = True if _preact_shortcuts or block_idx == 0 else False\n",
        "    \n",
        "    x = block_type(x, filters, stride, preact_block=preact_block)\n",
        "    for i in range(num_blocks-1):\n",
        "        x = block_type(x, filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Resnet(input_shape, n_classes, l2_reg=1e-4, group_sizes=(2, 2, 2), features=(16, 32, 64), strides=(1, 2, 2),\n",
        "           shortcut_type='B', block_type='preactivated', first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1},\n",
        "           dropout=0, cardinality=1, bootleneck_width=4, preact_shortcuts=True):\n",
        "    \n",
        "    global _regularizer, _shortcut_type, _preact_projection, _dropout, _cardinality, _bootleneck_width, _preact_shortcuts\n",
        "    _bootleneck_width = bootleneck_width # used in ResNeXts and bootleneck blocks\n",
        "    _regularizer = tf.keras.regularizers.l2(l2_reg)\n",
        "    _shortcut_type = shortcut_type # used in blocks\n",
        "    _cardinality = cardinality # used in ResNeXts\n",
        "    _dropout = dropout # used in Wide ResNets\n",
        "    _preact_shortcuts = preact_shortcuts\n",
        "    \n",
        "    block_types = {'preactivated': preactivation_block,\n",
        "                   'bootleneck': bootleneck_block,\n",
        "                   'original': original_block}\n",
        "    \n",
        "    selected_block = block_types[block_type]\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    flow = regularized_padded_conv(**first_conv)(inputs)\n",
        "    \n",
        "    if block_type == 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    for block_idx, (group_size, feature, stride) in enumerate(zip(group_sizes, features, strides)):\n",
        "        flow = group_of_blocks(flow,\n",
        "                               block_type=selected_block,\n",
        "                               num_blocks=group_size,\n",
        "                               block_idx=block_idx,\n",
        "                               filters=feature,\n",
        "                               stride=stride)\n",
        "    \n",
        "    if block_type != 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    flow = tf.keras.layers.GlobalAveragePooling2D()(flow)\n",
        "    outputs = tf.keras.layers.Dense(n_classes, kernel_regularizer=_regularizer)(flow)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_weights_func(model, model_name):\n",
        "    try: model.load_weights(os.path.join('saved_models', model_name + '.tf'))\n",
        "    except tf.errors.NotFoundError: print(\"No weights found for this model!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def cifar_wide_resnet(N, K, block_type='preactivated', shortcut_type='B', dropout=0, l2_reg=2.5e-4):\n",
        "    assert (N-4) % 6 == 0, \"N-4 has to be divisible by 6\"\n",
        "    lpb = (N-4) // 6 # layers per block - since N is total number of convolutional layers in Wide ResNet\n",
        "    model = Resnet(input_shape=(32, 32, 3), n_classes=10, l2_reg=l2_reg, group_sizes=(lpb, lpb, lpb), features=(16*K, 32*K, 64*K),\n",
        "                   strides=(1, 2, 2), first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1}, shortcut_type=shortcut_type,\n",
        "                   block_type=block_type, dropout=dropout, preact_shortcuts=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def WRN_28_2(shortcut_type='B', load_weights=False, dropout=0, l2_reg=2.5e-4):\n",
        "    model = cifar_wide_resnet(28, 2, 'preactivated', shortcut_type, dropout=dropout, l2_reg=l2_reg)\n",
        "    if load_weights: model = load_weights_func(model, 'cifar_WRN_28_10')\n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hfy2W4iGscd"
      },
      "source": [
        "# This cell is for CTAugment\n",
        "\n",
        "class CTAugment:\n",
        "\n",
        "  def __init__(self, n_classes, decay=0.99, threshold=0.80, depth=2, n_bins=17):\n",
        "    self.decay = decay\n",
        "    self.threshold = threshold\n",
        "    self.depth = depth\n",
        "    self.n_bins = n_bins\n",
        "    self.n_classes = n_classes\n",
        "    self.xforms = []\n",
        "    # self.bins = [[]]\n",
        "    # self.weights = [[]]\n",
        "\n",
        "    self.AUG_DICT = {\n",
        "        \"autocontrast\": {\"f\": self.autocontrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"blur\": {\"f\": self.blur, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"brightness\": {\"f\": self.brightness, \"weight\":[np.ones(self.n_bins)*1.0]},\n",
        "        \"color\": {\"f\": self.color, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"contrast\": {\"f\": self.contrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"cutout\": {\"f\": self.cutout, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"equalize\": {\"f\": self.equalize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"invert\": {\"f\": self.invert, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"identity\": {\"f\": self.identity, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"posterize\": {\"f\": self.posterize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"rescale\": {\"f\": self.rescale, \"weight\": [np.ones(self.n_bins)*1.0, np.ones(6)*1.0]},\n",
        "        \"rotate\": {\"f\": self.rotate, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"sharpness\": {\"f\": self.sharpness, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_x\": {\"f\": self.shear_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_y\": {\"f\": self.shear_y, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"smooth\": {\"f\": self.smooth, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"solarize\": {\"f\": self.solarize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_x\": {\"f\": self.translate_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_y\": {\"f\": self.translate_y, \"weight\": [np.ones(self.n_bins)*1.0]}\n",
        "    }\n",
        "    self.N = len(self.AUG_DICT.keys())\n",
        "    self.options = list(self.AUG_DICT.keys())\n",
        "\n",
        "    self.batch_choices = []\n",
        "    self.batch_bins = []\n",
        "\n",
        "  def weight_to_p(self, weight):\n",
        "        p = weight + (1 - self.decay)  # Avoid to have all zero.\n",
        "        p = p / p.max()\n",
        "        p[p < self.threshold] = 0\n",
        "        return p/np.sum(p)\n",
        "\n",
        "  def augment(self, x, uniform_bin_sampling=False):\n",
        "    aug_x = Image.fromarray(np.uint8(x))#255*x))\n",
        "\n",
        "    choices = [self.options[i] for i in np.random.choice(np.arange(self.N), self.depth, replace=False)]\n",
        "    bins = []\n",
        "\n",
        "    for k in range(self.depth):\n",
        "        choice_key = choices[k]\n",
        "        \n",
        "        transformation = self.AUG_DICT[choice_key][\"f\"]\n",
        "        # sample bins\n",
        "        if uniform_bin_sampling:\n",
        "          p = np.ones(self.N)/self.N\n",
        "        else:\n",
        "          w = self.AUG_DICT[choice_key][\"weight\"][0]\n",
        "          p = self.weight_to_p(w)\n",
        "        curr_bins = {}\n",
        "        curr_bins[\"bin\"] = np.random.choice(np.arange(self.n_bins), p=p)\n",
        "\n",
        "        if choice_key==\"rescale\":\n",
        "          if uniform_bin_sampling:\n",
        "            p = np.ones(6)/6\n",
        "          else:\n",
        "            w = self.AUG_DICT[choice_key][\"weight\"][1]\n",
        "            p = self.weight_to_p(w)\n",
        "          curr_bins[\"bin2\"] = np.random.choice(np.arange(6), p=p)\n",
        "\n",
        "        aug_x = transformation(aug_x, **curr_bins)\n",
        "        bins.append(curr_bins)\n",
        "\n",
        "    return np.array(aug_x), choices, bins\n",
        "\n",
        "  def augment_batch(self, batch):\n",
        "    aug_batch = tf.identity(batch)\n",
        "\n",
        "    #aug_batch = tf.map_fn(aug_batch, self.augment)\n",
        "    batch_choices = []\n",
        "    batch_bins = []\n",
        "    \n",
        "    if batch.ndim == 3:\n",
        "      sample, choices, bins = self.augment(sample)\n",
        "      batch_choices.append(choices)\n",
        "      batch_bins.append(bins)\n",
        "    elif batch.ndim == 4:\n",
        "      for sample in aug_batch:\n",
        "        sample, choices, bins = self.augment(sample)\n",
        "        batch_choices.append(choices)\n",
        "        batch_bins.append(bins)\n",
        "\n",
        "    return aug_batch, batch_choices, batch_bins\n",
        "\n",
        "  def update_weights(self, label, pred, choices, bins):\n",
        "    omega = 1 - (1 / (2*self.n_classes)) * np.sum(tf.math.abs(label - pred))\n",
        "\n",
        "    for k, choice in enumerate(choices):\n",
        "      w = self.AUG_DICT[choice][\"weight\"][0]\n",
        "      bin = bins[k][\"bin\"]\n",
        "      self.AUG_DICT[choice][\"weight\"][0][bin] = self.decay * w[bin] + (1 - self.decay) * omega\n",
        "      # print(self.AUG_DICT[choice][\"weight\"][0])\n",
        "      if choices[k] == \"rescale\":\n",
        "        w = self.AUG_DICT[choice][\"weight\"][1]\n",
        "        bin = bins[k][\"bin2\"]\n",
        "        self.AUG_DICT[choice][\"weight\"][1][bin] = self.decay * w[bin] + (1 - self.decay) * omega\n",
        "\n",
        "\n",
        "\n",
        "  def update_weights_batch(self, labels, preds, choices, bins):\n",
        "    [self.update_weights(l, p, c, b) for l, p, c, b in zip(labels, preds, choices, bins)]\n",
        "\n",
        "  def get_param(self, r_min, r_max, bin):\n",
        "      possible_value = np.linspace(r_min, r_max, self.n_bins)\n",
        "      return possible_value[bin]\n",
        "\n",
        "  def autocontrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.autocontrast(x), param)\n",
        "  \n",
        "  def blur(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.BLUR), param)\n",
        "  \n",
        "  def brightness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Brightness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def color(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Color(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def contrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Contrast(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def cutout(self, x, bin):\n",
        "    \"\"\"Taken directlly from FixMatch code\"\"\"\n",
        "    level = self.get_param(0, 0.5, bin)\n",
        "\n",
        "    size = 1 + int(level * min(x.size) * 0.499)\n",
        "    img_height, img_width = x.size\n",
        "    height_loc = np.random.randint(low=0, high=img_height)\n",
        "    width_loc = np.random.randint(low=0, high=img_width)\n",
        "    upper_coord = (max(0, height_loc - size // 2), max(0, width_loc - size // 2))\n",
        "    lower_coord = (min(img_height, height_loc + size // 2), min(img_width, width_loc + size // 2))\n",
        "    pixels = x.load()  # create the pixel map\n",
        "    for i in range(upper_coord[0], lower_coord[0]):  # for every col:\n",
        "        for j in range(upper_coord[1], lower_coord[1]):  # For every row\n",
        "            pixels[i, j] = (127, 127, 127)  # set the color accordingly\n",
        "    return x\n",
        "\n",
        "  def equalize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.equalize(x), param)\n",
        "\n",
        "  def invert(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.invert(x), param)\n",
        "  \n",
        "  def identity(self, x, bin):\n",
        "      return x\n",
        "\n",
        "  def posterize(self, x, bin):\n",
        "      param = int(self.get_param(0, 8, bin))\n",
        "      return ImageOps.posterize(x, param)\n",
        "\n",
        "  def rescale(self, x, bin, bin2):\n",
        "      param = self.get_param(0.5, 1, bin)\n",
        "      methods = (Image.ANTIALIAS, Image.BICUBIC, Image.BILINEAR, Image.BOX, Image.HAMMING, Image.NEAREST)\n",
        "      method = methods[bin2]\n",
        "      s = x.size\n",
        "      scale = param*0.25\n",
        "      crop = (scale * s[0], scale * s[1], s[0] * (1 - scale), s[1] * (1 - scale))\n",
        "      return x.crop(crop).resize(x.size, method)\n",
        "\n",
        "  def rotate(self, x, bin):\n",
        "      param = self.get_param(-45, 45, bin)\n",
        "      angle = int(np.round((2 * param - 1) * 45))\n",
        "      return x.rotate(angle)\n",
        "\n",
        "  def sharpness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Sharpness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def shear_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, shear, 0, 0, 1, 0))\n",
        "\n",
        "  def shear_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, shear, 1, 0))\n",
        "\n",
        "  def smooth(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.SMOOTH), param)\n",
        "\n",
        "  def solarize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      th = int(param * 255.999)\n",
        "      return ImageOps.solarize(x, th)\n",
        "\n",
        "  def translate_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, delta, 0, 1, 0))\n",
        "\n",
        "  def translate_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, 0, 1, delta))\n",
        "\n",
        "\n",
        "class OurCosineDecay(tf.keras.experimental.CosineDecay):\n",
        "\n",
        "  def __call__(self, step):\n",
        "    print(\"HEJ\")\n",
        "    with ops.name_scope_v2(self.name or \"CosineDecay\"):\n",
        "      initial_learning_rate = ops.convert_to_tensor_v2(\n",
        "          self.initial_learning_rate, name=\"initial_learning_rate\")\n",
        "      dtype = initial_learning_rate.dtype\n",
        "      decay_steps = math_ops.cast(self.decay_steps, dtype)\n",
        "\n",
        "      global_step_recomp = math_ops.cast(step, dtype)\n",
        "      global_step_recomp = math_ops.minimum(global_step_recomp, decay_steps)\n",
        "      completed_fraction = global_step_recomp / decay_steps\n",
        "      cosine_decayed = math_ops.cos(\n",
        "          constant_op.constant(7/16 * math.pi) * completed_fraction)\n",
        "\n",
        "      decayed = (1 - self.alpha) * cosine_decayed + self.alpha\n",
        "      return math_ops.multiply(initial_learning_rate, decayed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MY99qVwV6hh"
      },
      "source": [
        "def training(model, ds_l, ds_u, hparams, mean=None, std=None,\n",
        "                   val_interval=2000, log_interval=200, batch_size=128):\n",
        "\n",
        "    def train_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        return x, y\n",
        "\n",
        "    def valid_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)\n",
        "        return x, y\n",
        "\n",
        "    def weak_transformation(x):\n",
        "      x = tf.image.random_flip_left_right(x)\n",
        "      max_shift = tf.cast(x.shape[1]*0.125, dtype=tf.dtypes.int32)\n",
        "      shift = tf.random.uniform([x.shape[0], 2], minval=-max_shift, maxval=max_shift, dtype=tf.dtypes.int32)\n",
        "      \n",
        "      return tfa.image.translate(x, tf.cast(shift, tf.dtypes.float32))\n",
        "      \n",
        "\n",
        "    def pseudolabel(class_dist):\n",
        "        argmax = tf.math.argmax(class_dist, axis=1)\n",
        "        return tf.one_hot(argmax, class_dist.shape[1])\n",
        "\n",
        "    def threshold_gate(one_hot, logits, threshold):\n",
        "        max_probs = tf.math.multiply(one_hot, tf.nn.softmax(logits))\n",
        "        return tf.cast(max_probs > threshold, max_probs.dtype)# * max_probs\n",
        "\n",
        "    \n",
        "    #@tf.function\n",
        "    def step(x_l, y_l, x_u, training):\n",
        "        with tf.GradientTape() as tape:            \n",
        "\n",
        "            # labeled data\n",
        "            x_l_weak = weak_transformation(x_l)\n",
        "            output_l = model(x_l_weak, training)\n",
        "            loss_l = loss_fn(y_l, output_l)\n",
        "\n",
        "            \n",
        "            # unlabeled data\n",
        "            x_u_weak = weak_transformation(x_u)\n",
        "            output_u_weak = model(x_u_weak, training)  # should this be training or not?\n",
        "            y_u = pseudolabel(output_u_weak)\n",
        "            y_u = threshold_gate(y_u, output_u_weak, hparams['treshold'])\n",
        "\n",
        "            x_u_strong, choices, bins = cta.augment_batch(x)\n",
        "            output_u_strong = model(x_u_strong, training)\n",
        "            cta.update_weights_batch(y_u, outputs_u_strong, choices, bins)\n",
        "            \n",
        "            unlabeled_loss = loss_fn(y_u, output_u_strong)\n",
        "            \n",
        "\n",
        "            #add losses together\n",
        "            loss = labeled_loss + hparams['lamda'] * unlabeled_loss\n",
        "\n",
        "\n",
        "        if training:\n",
        "            gradients = tape.gradient(loss, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        accuracy(y, outs)\n",
        "        cls_loss(c_loss)\n",
        "        reg_loss(r_loss)\n",
        "\n",
        "    schedule = OurCosineDecay(hparams['eta'], hparams['K'])\n",
        "    optimizer = tf.keras.optimizers.SGD(schedule, momentum=hparams['beta'], nesterov=hparams['nesterov'])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    cta = CTAugment(hparams['cta_classes'], hparams['cta_decay'], hparams['cta_threshold'], hparams['cta_depth'])\n",
        "    \n",
        "    # split into batches\n",
        "    #img_l = tf.split(img_l, hparams['batch_size'], axis=0, name='split')\n",
        "    ds_l = ds_l.map(train_prep).batch(hparams['batch_size']).prefetch(-1)\n",
        "    ds_u = ds_u.map(train_prep).batch(hparams['batch_size']).prefetch(-1)\n",
        "\n",
        "\n",
        "    #runid = run_name + '_x' + str(np.random.randint(10000))\n",
        "    #writer = tf.summary.create_file_writer(logdir + '/' + runid)\n",
        "    accuracy = tf.metrics.SparseCategoricalAccuracy()\n",
        "    cls_loss = tf.metrics.Mean()\n",
        "    reg_loss = tf.metrics.Mean()\n",
        "    \n",
        "    #print(f\"RUNID: {runid}\")\n",
        "    #tf.keras.utils.plot_model(model)#, os.path.join('saved_plots', runid + '.png'))    \n",
        "\n",
        "    training_step = 0\n",
        "    best_validation_acc = 0\n",
        "    epochs = 1\n",
        "\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        #for x, y in tqdm( ds_l.take(val_interval), desc=f'epoch {epoch+1}/{epochs}',\n",
        "        #                 total=val_interval, ncols=100, ascii=True):\n",
        "        for (x_l, y_l), (x_u, _) in tqdm( zip(ds_l, ds_u), desc=f'epoch {epoch+1}/{epochs}',\n",
        "                         total=val_interval, ncols=100, ascii=True):\n",
        "\n",
        "            tf.print(x_l.shape)\n",
        "            tf.print(y_l.shape)            \n",
        "            tf.print(x_u.shape)\n",
        "\n",
        "\n",
        "            training_step += 1\n",
        "            step(x_l, y_l, x_u, training=True)\n",
        "\n",
        "            if training_step % log_interval == 0:\n",
        "                #with writer.as_default():\n",
        "                    c_loss, r_loss, err = cls_loss.result(), reg_loss.result(), 1-accuracy.result()\n",
        "                    print(f\" c_loss: {c_loss:^6.3f} | r_loss: {r_loss:^6.3f} | err: {err:^6.3f}\", end='\\r')\n",
        "\n",
        "                    tf.summary.scalar('train/error_rate', err, training_step)\n",
        "                    tf.summary.scalar('train/classification_loss', c_loss, training_step)\n",
        "                    tf.summary.scalar('train/regularization_loss', r_loss, training_step)\n",
        "                    tf.summary.scalar('train/learnig_rate', optimizer._decayed_lr('float32'), training_step)\n",
        "                    cls_loss.reset_states()\n",
        "                    reg_loss.reset_states()\n",
        "                    accuracy.reset_states()\n",
        "\n",
        "        for x, y in ds['test']:\n",
        "            step(x, y, training=False)\n",
        "\n",
        "        #with writer.as_default(): TBULATE THE FOLLOWING WHEN UNCOMMENTING!\n",
        "        tf.summary.scalar('test/classification_loss', cls_loss.result(), step=training_step)\n",
        "        tf.summary.scalar('test/error_rate', 1-accuracy.result(), step=training_step)\n",
        "            \n",
        "        if accuracy.result() > best_validation_acc:\n",
        "                best_validation_acc = accuracy.result()\n",
        "                #model.save_weights(os.path.join('saved_models', runid + '.tf'))\n",
        "                \n",
        "        cls_loss.reset_states()\n",
        "        accuracy.reset_states()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8wdZaaZ25bY"
      },
      "source": [
        "\n",
        "# hyperparams\n",
        "lamda = 1     # proportion of unlabeled loss in total loss\n",
        "eta = 0.03    # learning rate\n",
        "beta = 0.09   # momentum\n",
        "tau = 0.95    # threshold in pseudo-labeling\n",
        "mu = 0.7      # proportion of unlabeled samples in batch\n",
        "B = 64        # number of labeled examples in batch(in training)\n",
        "K = 2 ** 20\n",
        "nesterov = False\n",
        "batch_size = 2  # should be 64?\n",
        "# weight decay\n",
        "# SGD instead of Adam\n",
        "\n",
        "\n",
        "#CTAugment params\n",
        "cta_classes = 10\n",
        "cta_decay = 0.99\n",
        "cta_depth = 2\n",
        "cta_threshold = 0.8\n",
        "\n",
        "hparams = {'lamda': lamda, 'eta': eta, 'beta': beta, 'tau': tau, 'mu': mu, 'B': B, 'K': K, 'nesterov': False, 'batch_size': batch_size,\n",
        "           'cta_classes': cta_classes, 'cta_decay': cta_decay, 'cta_depth': cta_depth, 'cta_threshold': cta_threshold}"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9vH0aDt5Ry"
      },
      "source": [
        "model = WRN_28_2()\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tNCCUFNSlOP"
      },
      "source": [
        "def ParseFunction(serialized, image_shape=[32, 32, 3]):\n",
        "    features = {'image': tf.io.FixedLenFeature([], tf.string),\n",
        "                'label': tf.io.FixedLenFeature([], tf.int64)}\n",
        "\n",
        "    parsed_example = tf.io.parse_single_example(serialized=serialized, features=features) \n",
        "    image = tf.image.decode_image(parsed_example['image'])\n",
        "    image.set_shape(image_shape)\n",
        "    # image = tf.cast(image, tf.float32) * (2.0 / 255) - 1.0\n",
        "    data = dict(image=image, label=parsed_example['label'])\n",
        "    return data\n",
        "\n",
        "def stl_ParseFunction(input):\n",
        "  return ParseFunction(serialized=input, image_shape=[96, 96, 3])\n",
        "\n",
        "def LoadData(filename, tensor=False):\n",
        "  dataset = tf.data.TFRecordDataset(filename)\n",
        "  dataset = dataset.map(ParseFunction)\n",
        "  \n",
        "  # it = tf.compat.v1.data.make_one_shot_iterator(dataset) # Never used?\n",
        "  images = np.stack([x['image'] for x in dataset])\n",
        "  labels = np.stack([x['label'] for x in dataset])\n",
        "\n",
        "  if tensor:\n",
        "      return tf.data.Dataset.from_tensor_slices((images, labels))\n",
        "  else:\n",
        "      return images, labels\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bkYlQ3BbM5A"
      },
      "source": [
        "fpath = '/content/drive/My Drive/Colab Notebooks/cifar10.3@10-label.tfrecord'\n",
        "\n",
        "im, ls = LoadData(fpath)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsDerohJ4RAw"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_O71Qt-X7sfa",
        "outputId": "cdf5af67-c9a7-4993-e00d-c93e01a2623f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def test_error(model, test_data, test_labels):\n",
        "  out = model(test_data)\n",
        "  out_l = tf.math.argmax(out, axis=1)\n",
        "  return np.sum(out_l == test_labels)/len(test_labels)\n",
        "\n",
        "test_error(model, im, ls)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQDq8TrkQ72F"
      },
      "source": [
        "\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ET93aSebHs"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctr7_6KvamqI"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_P-BZbCa0HS"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfACBOMva4_E"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCVeRzVwbFam"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNlFiu2Rzf5C"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JAbVTvztHEJ"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCLINL2XWLhR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1xOtqKpuLZ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}