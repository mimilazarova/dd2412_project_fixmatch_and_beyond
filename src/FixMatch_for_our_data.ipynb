{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FixMatch_training_loop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmfb90N9fjlY",
        "outputId": "9ae3d29b-ebf5-45cd-d308-ee7fa688c7b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "pip install tensorflow-addons==0.11.1"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons==0.11.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/51/8e5bb7649ac136292aefef6ea0172d10cc23a26dcda093c62637585bc05e/tensorflow_addons-0.11.1-cp36-cp36m-manylinux2010_x86_64.whl (1.1MB)\n",
            "\r\u001b[K     |▎                               | 10kB 23.1MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 19.7MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 24.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40kB 15.1MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51kB 14.1MB/s eta 0:00:01\r\u001b[K     |█▉                              | 61kB 12.4MB/s eta 0:00:01\r\u001b[K     |██                              | 71kB 12.4MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81kB 12.1MB/s eta 0:00:01\r\u001b[K     |██▊                             | 92kB 13.2MB/s eta 0:00:01\r\u001b[K     |███                             | 102kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▋                            | 122kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 153kB 13.1MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████                           | 174kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 184kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 204kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 215kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 245kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 256kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 266kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 276kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 286kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 296kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 307kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 317kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 327kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 337kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 348kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 358kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 368kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 389kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 399kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████                    | 409kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 419kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 430kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 440kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 460kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 471kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 481kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 491kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 501kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 512kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 522kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 532kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 542kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 563kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 573kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 583kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 593kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 604kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 614kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 624kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 634kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 645kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 655kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 665kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 675kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 686kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 696kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 706kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 716kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 727kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 737kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 747kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 757kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 768kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 778kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 788kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 798kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 808kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 819kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 829kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 839kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 849kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 860kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 870kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 880kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 890kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 901kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 911kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 921kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 931kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 942kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 952kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 962kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 972kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 983kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 993kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.0MB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1MB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1MB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons==0.11.1) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "  Found existing installation: tensorflow-addons 0.8.3\n",
            "    Uninstalling tensorflow-addons-0.8.3:\n",
            "      Successfully uninstalled tensorflow-addons-0.8.3\n",
            "Successfully installed tensorflow-addons-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXaHCn3SUuY7"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def regularized_padded_conv(*args, **kwargs):\n",
        "    return tf.keras.layers.Conv2D(*args, **kwargs, padding='same', kernel_regularizer=_regularizer,\n",
        "                                  kernel_initializer='he_normal', use_bias=False)\n",
        "\n",
        "\n",
        "def BN_ReLU(x):\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    return tf.keras.layers.ReLU()(x)\n",
        "\n",
        "\n",
        "def shortcut(x, filters, stride, mode):\n",
        "    if x.shape[-1] == filters:\n",
        "        return x\n",
        "    elif mode == 'B':\n",
        "        return regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "    elif mode == 'B_original':\n",
        "        x = regularized_padded_conv(filters, 1, strides=stride)(x)\n",
        "        return tf.keras.layers.BatchNormalization()(x)\n",
        "    elif mode == 'A':\n",
        "        return tf.pad(tf.keras.layers.MaxPool2D(1, stride)(x) if stride>1 else x,\n",
        "                      paddings=[(0, 0), (0, 0), (0, 0), (0, filters - x.shape[-1])])\n",
        "    else:\n",
        "        raise KeyError(\"Parameter shortcut_type not recognized!\")\n",
        "    \n",
        "\n",
        "def original_block(x, filters, stride=1, **kwargs):\n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(x)\n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    c2 = tf.keras.layers.BatchNormalization()(c2)\n",
        "    \n",
        "    mode = 'B_original' if _shortcut_type == 'B' else _shortcut_type\n",
        "    x = shortcut(x, filters, stride, mode=mode)\n",
        "    return tf.keras.layers.ReLU()(x + c2)\n",
        "    \n",
        "    \n",
        "def preactivation_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "        \n",
        "    c1 = regularized_padded_conv(filters, 3, strides=stride)(flow)\n",
        "    if _dropout:\n",
        "        c1 = tf.keras.layers.Dropout(_dropout)(c1)\n",
        "        \n",
        "    c2 = regularized_padded_conv(filters, 3)(BN_ReLU(c1))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c2\n",
        "\n",
        "\n",
        "def bootleneck_block(x, filters, stride=1, preact_block=False):\n",
        "    flow = BN_ReLU(x)\n",
        "    if preact_block:\n",
        "        x = flow\n",
        "         \n",
        "    c1 = regularized_padded_conv(filters//_bootleneck_width, 1)(flow)\n",
        "    c2 = regularized_padded_conv(filters//_bootleneck_width, 3, strides=stride)(BN_ReLU(c1))\n",
        "    c3 = regularized_padded_conv(filters, 1)(BN_ReLU(c2))\n",
        "    x = shortcut(x, filters, stride, mode=_shortcut_type)\n",
        "    return x + c3\n",
        "\n",
        "\n",
        "def group_of_blocks(x, block_type, num_blocks, filters, stride, block_idx=0):\n",
        "    global _preact_shortcuts\n",
        "    preact_block = True if _preact_shortcuts or block_idx == 0 else False\n",
        "    \n",
        "    x = block_type(x, filters, stride, preact_block=preact_block)\n",
        "    for i in range(num_blocks-1):\n",
        "        x = block_type(x, filters)\n",
        "    return x\n",
        "\n",
        "\n",
        "def Resnet(input_shape, n_classes, l2_reg=1e-4, group_sizes=(2, 2, 2), features=(16, 32, 64), strides=(1, 2, 2),\n",
        "           shortcut_type='B', block_type='preactivated', first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1},\n",
        "           dropout=0, cardinality=1, bootleneck_width=4, preact_shortcuts=True):\n",
        "    \n",
        "    global _regularizer, _shortcut_type, _preact_projection, _dropout, _cardinality, _bootleneck_width, _preact_shortcuts\n",
        "    _bootleneck_width = bootleneck_width # used in ResNeXts and bootleneck blocks\n",
        "    _regularizer = tf.keras.regularizers.l2(l2_reg)\n",
        "    _shortcut_type = shortcut_type # used in blocks\n",
        "    _cardinality = cardinality # used in ResNeXts\n",
        "    _dropout = dropout # used in Wide ResNets\n",
        "    _preact_shortcuts = preact_shortcuts\n",
        "    \n",
        "    block_types = {'preactivated': preactivation_block,\n",
        "                   'bootleneck': bootleneck_block,\n",
        "                   'original': original_block}\n",
        "    \n",
        "    selected_block = block_types[block_type]\n",
        "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
        "    flow = regularized_padded_conv(**first_conv)(inputs)\n",
        "    \n",
        "    if block_type == 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    for block_idx, (group_size, feature, stride) in enumerate(zip(group_sizes, features, strides)):\n",
        "        flow = group_of_blocks(flow,\n",
        "                               block_type=selected_block,\n",
        "                               num_blocks=group_size,\n",
        "                               block_idx=block_idx,\n",
        "                               filters=feature,\n",
        "                               stride=stride)\n",
        "    \n",
        "    if block_type != 'original':\n",
        "        flow = BN_ReLU(flow)\n",
        "    \n",
        "    flow = tf.keras.layers.GlobalAveragePooling2D()(flow)\n",
        "    outputs = tf.keras.layers.Dense(n_classes, kernel_regularizer=_regularizer)(flow)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_weights_func(model, model_name):\n",
        "    try: model.load_weights(os.path.join('saved_models', model_name + '.tf'))\n",
        "    except tf.errors.NotFoundError: print(\"No weights found for this model!\")\n",
        "    return model\n",
        "\n",
        "\n",
        "def cifar_wide_resnet(N, K, block_type='preactivated', shortcut_type='B', dropout=0, l2_reg=2.5e-4):\n",
        "    assert (N-4) % 6 == 0, \"N-4 has to be divisible by 6\"\n",
        "    lpb = (N-4) // 6 # layers per block - since N is total number of convolutional layers in Wide ResNet\n",
        "    model = Resnet(input_shape=(32, 32, 3), n_classes=10, l2_reg=l2_reg, group_sizes=(lpb, lpb, lpb), features=(16*K, 32*K, 64*K),\n",
        "                   strides=(1, 2, 2), first_conv={\"filters\": 16, \"kernel_size\": 3, \"strides\": 1}, shortcut_type=shortcut_type,\n",
        "                   block_type=block_type, dropout=dropout, preact_shortcuts=True)\n",
        "    return model\n",
        "\n",
        "\n",
        "def WRN_28_2(shortcut_type='B', load_weights=False, dropout=0, l2_reg=2.5e-4):\n",
        "    model = cifar_wide_resnet(28, 2, 'preactivated', shortcut_type, dropout=dropout, l2_reg=l2_reg)\n",
        "    if load_weights: model = load_weights_func(model, 'cifar_WRN_28_10')\n",
        "    return model"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hfy2W4iGscd"
      },
      "source": [
        "import tensorflow_probability as tfp\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance, ImageFilter\n",
        "\n",
        "\n",
        "class CTAugment:\n",
        "\n",
        "  def __init__(self, n_classes, decay=0.99, threshold=0.85, depth=2, n_bins=17):\n",
        "    self.decay = decay\n",
        "    self.threshold = threshold\n",
        "    self.depth = depth\n",
        "    self.n_bins = n_bins\n",
        "    self.n_classes = n_classes\n",
        "  \n",
        "    # we need some way of storing functions so that we can randomly sample\n",
        "    # from them. The format below might not be perfect but it is nice if we \n",
        "    # can generate a index i wish with which we can access the ith\n",
        "    # transformation, its corresponding bins and their weights\n",
        "    self.xforms = []\n",
        "    self.bins = [[]]\n",
        "    self.weights = [[]]\n",
        "\n",
        "    self.AUG_DICT = {\n",
        "        \"autocontrast\": {\"f\": self.autocontrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"blur\": {\"f\": self.blur, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"brightness\": {\"f\": self.brightness, \"weight\":[np.ones(self.n_bins)*1.0]},\n",
        "        \"color\": {\"f\": self.color, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"contrast\": {\"f\": self.contrast, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"cutout\": {\"f\": self.cutout, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"equalize\": {\"f\": self.equalize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"invert\": {\"f\": self.invert, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"identity\": {\"f\": self.identity, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"posterize\": {\"f\": self.posterize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"rescale\": {\"f\": self.rescale, \"weight\": [np.ones(self.n_bins)*1.0, np.ones(6)*1.0]},\n",
        "        \"rotate\": {\"f\": self.rotate, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"sharpness\": {\"f\": self.sharpness, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_x\": {\"f\": self.shear_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"shear_y\": {\"f\": self.shear_y, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"smooth\": {\"f\": self.smooth, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"solarize\": {\"f\": self.solarize, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_x\": {\"f\": self.translate_x, \"weight\": [np.ones(self.n_bins)*1.0]},\n",
        "        \"translate_y\": {\"f\": self.translate_y, \"weight\": [np.ones(self.n_bins)*1.0]}\n",
        "    }\n",
        "    self.N = len(self.AUG_DICT.keys())\n",
        "    self.options = list(self.AUG_DICT.keys())\n",
        "\n",
        "    self.batch_choices = []\n",
        "    self.batch_bins = []\n",
        "\n",
        "  def weight_to_p(self, weight):\n",
        "        p = weight + (1 - self.decay)  # Avoid to have all zero.\n",
        "        p = p / p.max()\n",
        "        p[p < self.threshold] = 0\n",
        "        return p/np.sum(p)\n",
        "\n",
        "  def augment(self, x):\n",
        "    aug_x = Image.fromarray(np.uint8(255*x))\n",
        "\n",
        "\n",
        "    choices = [self.options[i] for i in np.random.choice(np.arange(self.N), self.depth, replace=False)]\n",
        "    bins = []\n",
        "\n",
        "    for k in range(self.depth):\n",
        "        choice_key = choices[k]\n",
        "        \n",
        "        transformation = self.AUG_DICT[choice_key][\"f\"]\n",
        "        # pick weights for correpsonding function and set weigths to 0 if they \n",
        "        # are less than 0.8\n",
        "        w = self.AUG_DICT[choice_key][\"weight\"][0]\n",
        "        p = self.weight_to_p(w)\n",
        "        curr_bins = {}\n",
        "        curr_bins[\"bin\"] = np.random.choice(np.arange(self.n_bins), p=p)\n",
        "\n",
        "        if choice_key==\"rescale\":\n",
        "          w = self.AUG_DICT[choice_key][\"weight\"][1]\n",
        "          p = self.weight_to_p(w)\n",
        "          curr_bins[\"bin2\"] = np.random.choice(np.arange(6), p=p)\n",
        "\n",
        "        # we should probably copy here so we do not overwrite original\n",
        "        aug_x = transformation(aug_x, **curr_bins)\n",
        "        bins.append(curr_bins)\n",
        "\n",
        "    return np.array(aug_x), choices, bins\n",
        "\n",
        "  def augment_batch(self, batch):\n",
        "    aug_batch = tf.identity(batch)\n",
        "\n",
        "    #aug_batch = tf.map_fn(aug_batch, self.augment)\n",
        "    batch_choices = []\n",
        "    batch_bins = []\n",
        "    \n",
        "    if batch.ndim == 3:\n",
        "      sample, choices, bins = self.augment(sample)\n",
        "      batch_choices.append(choices)\n",
        "      batch_bins.append(bins)\n",
        "    elif batch.ndim == 4:\n",
        "      for sample in aug_batch:\n",
        "        sample, choices, bins = self.augment(sample)\n",
        "        batch_choices.append(choices)\n",
        "        batch_bins.append(bins)\n",
        "\n",
        "    return aug_batch, batch_choices, batch_bins\n",
        "\n",
        "  def update_weights(self, label, pred, choices, bins):\n",
        "    omega = 1 - 1 / (2*self.n_classes) * np.sum(tf.math.abs(label - pred))\n",
        "\n",
        "    for k in range(self.depth):\n",
        "\n",
        "      w = self.AUG_DICT[choices[k]][\"weight\"][0]\n",
        "      #tmp = np.copy(w)\n",
        "      w[bins[k][\"bin\"]] = self.decay * w[bins[k][\"bin\"]] + (1 - self.decay) * omega\n",
        "      #print(tmp-w)\n",
        "      if choices[k] == \"rescale\":\n",
        "        w = self.AUG_DICT[choices[k]][\"weight\"][1]\n",
        "        #tmp = np.copy(w)\n",
        "        w[bins[k][\"bin2\"]] = self.decay * w[bins[k][\"bin2\"]] + (1 - self.decay) * omega\n",
        "        #print(tmp-w)\n",
        "\n",
        "\n",
        "  def update_weights_batch(self, labels, preds, choices, bins):\n",
        "    [self.update_weights(l, p, c, b) for l, p, c, b in zip(labels, preds, choices, bins)]\n",
        "\n",
        "  def get_param(self, r_min, r_max, bin):\n",
        "      possible_value = np.linspace(r_min, r_max, self.n_bins)\n",
        "      return possible_value[bin]\n",
        "\n",
        "  def autocontrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.autocontrast(x), param)\n",
        "  \n",
        "  def blur(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.BLUR), param)\n",
        "  \n",
        "  def brightness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Brightness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def color(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Color(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def contrast(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Contrast(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def cutout(self, x, bin):\n",
        "    \"\"\"Taken directlly from FixMatch code\"\"\"\n",
        "    level = self.get_param(0, 0.5, bin)\n",
        "\n",
        "    size = 1 + int(level * min(x.size) * 0.499)\n",
        "    img_height, img_width = x.size\n",
        "    height_loc = np.random.randint(low=0, high=img_height)\n",
        "    width_loc = np.random.randint(low=0, high=img_width)\n",
        "    upper_coord = (max(0, height_loc - size // 2), max(0, width_loc - size // 2))\n",
        "    lower_coord = (min(img_height, height_loc + size // 2), min(img_width, width_loc + size // 2))\n",
        "    pixels = x.load()  # create the pixel map\n",
        "    for i in range(upper_coord[0], lower_coord[0]):  # for every col:\n",
        "        for j in range(upper_coord[1], lower_coord[1]):  # For every row\n",
        "            pixels[i, j] = (127, 127, 127)  # set the color accordingly\n",
        "    return x\n",
        "\n",
        "  def equalize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.equalize(x), param)\n",
        "\n",
        "  def invert(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, ImageOps.invert(x), param)\n",
        "  \n",
        "  def identity(self, x, bin):\n",
        "      return x\n",
        "\n",
        "  def posterize(self, x, bin):\n",
        "      param = int(self.get_param(0, 8, bin))\n",
        "      return ImageOps.posterize(x, param)\n",
        "\n",
        "  def rescale(self, x, bin, bin2):\n",
        "      param = self.get_param(0.5, 1, bin)\n",
        "      methods = (Image.ANTIALIAS, Image.BICUBIC, Image.BILINEAR, Image.BOX, Image.HAMMING, Image.NEAREST)\n",
        "      method = methods[bin2]\n",
        "      s = x.size\n",
        "      scale = param*0.25\n",
        "      crop = (scale * s[0], scale * s[1], s[0] * (1 - scale), s[1] * (1 - scale))\n",
        "      return x.crop(crop).resize(x.size, method)\n",
        "\n",
        "  def rotate(self, x, bin):\n",
        "      param = self.get_param(-45, 45, bin)\n",
        "      angle = int(np.round((2 * param - 1) * 45))\n",
        "      return x.rotate(angle)\n",
        "\n",
        "  def sharpness(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return ImageEnhance.Sharpness(x).enhance(0.1 + 1.9*param)\n",
        "\n",
        "  def shear_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, shear, 0, 0, 1, 0))\n",
        "\n",
        "  def shear_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      shear = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, shear, 1, 0))\n",
        "\n",
        "  def smooth(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      return Image.blend(x, x.filter(ImageFilter.SMOOTH), param)\n",
        "\n",
        "  def solarize(self, x, bin):\n",
        "      param = self.get_param(0, 1, bin)\n",
        "      th = int(param * 255.999)\n",
        "      return ImageOps.solarize(x, th)\n",
        "\n",
        "  def translate_x(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, delta, 0, 1, 0))\n",
        "\n",
        "  def translate_y(self, x, bin):\n",
        "      param = self.get_param(-0.3, 0.3, bin)\n",
        "      delta = (2 * param - 1) * 0.3\n",
        "      return x.transform(x.size, Image.AFFINE, (1, 0, 0, 0, 1, delta))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9nFO9BDTOXD"
      },
      "source": [
        "class OurCosineDecay(tf.keras.experimental.CosineDecay):\n",
        "  \n",
        "  def decayed_learning_rate(step):\n",
        "    old_lr = super(OurCosineDecay, self).decayed_learning_rate(step)\n",
        "\n",
        "    #new_lr\n",
        "    step = min(step, decay_steps)\n",
        "    cosine_decay = cos(7 * pi * step / (16 * decay_steps))\n",
        "    return initial_learning_rate * cosine_decay"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MY99qVwV6hh"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' \n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_addons as tfa\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "\n",
        "def training(model, ds_l, ds_u, hparams, mean=None, std=None, lr_values=[0.01, 0.1, 0.01, 0.001], lr_boundaries=[400, 32000, 48000, 64000],\n",
        "                   val_interval=2000, log_interval=200, batch_size=128):\n",
        "\n",
        "    #schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=lr_boundaries[:-1], values=lr_values)\n",
        "    schedule = OurCosineDecay(hparams['eta'], hparams['K'])\n",
        "    optimizer = tf.keras.optimizers.SGD(schedule, momentum=hparams['beta'], nesterov=hparmas['nesterov'])\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    cta = CTAugment(hparams['cta_classes'], hparams['cta_decay'], hparams['cta_threshold'], hparams['cta_depth'])\n",
        "    \n",
        "    def train_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        #x = tf.image.pad_to_bounding_box(x, 4, 4, 40, 40) #must fix ds independent shape\n",
        "        #x = tf.image.random_crop(x, (32, 32, 3))          #must fix ds independent shape\n",
        "        if mean is not None and std is not None:\n",
        "          x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "    def valid_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        if mean is not None and std is not None:\n",
        "          x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "\n",
        "    #ds['train'] = ds['train'].map(train_prep).shuffle(10000).repeat().batch(batch_size).prefetch(-1)\n",
        "    ds_l['train'] = ds_l['train'].map(train_prep).batch(hparams['B']).prefetch(-1)\n",
        "    ds_u['train'] = ds_u['train'].map(train_prep).batch(hparams['mu'] * hparams['B']).prefetch(-1)\n",
        "    \n",
        "    ds_l['test'] = ds_l['test'].map(valid_prep).batch(batch_size*4).prefetch(-1)\n",
        "\n",
        "    #runid = run_name + '_x' + str(np.random.randint(10000))\n",
        "    #writer = tf.summary.create_file_writer(logdir + '/' + runid)\n",
        "    accuracy = tf.metrics.SparseCategoricalAccuracy()\n",
        "    cls_loss = tf.metrics.Mean()\n",
        "    reg_loss = tf.metrics.Mean()\n",
        "    \n",
        "    #print(f\"RUNID: {runid}\")\n",
        "    #tf.keras.utils.plot_model(model)#, os.path.join('saved_plots', runid + '.png'))\n",
        "\n",
        "    def weak_transformation(x):\n",
        "      x = tf.image.random_flip_left_right(x)\n",
        "      max_shift = tf.cast(x.shape[1]*0.125, dtype=tf.dtypes.int32)\n",
        "      shift = tf.random.uniform([x.shape[0], 2], minval=-max_shift, maxval=max_shift, dtype=tf.dtypes.int32)\n",
        "      return tfa.image.translate(x, tf.cast(shift, tf.dtypes.float32))\n",
        "      \n",
        "\n",
        "    def pseudolabel(class_dist):\n",
        "        argmax = tf.math.argmax(class_dist, axis=1)\n",
        "        return tf.one_hot(argmax, class_dist.shape[1])\n",
        "\n",
        "    def threshold_gate(one_hot, logits, threshold):\n",
        "        max_probs = tf.math.multiply(one_hot, tf.nn.softmax(logits))\n",
        "        return tf.cast(max_probs > threshold, max_probs.dtype)# * max_probs\n",
        "\n",
        "    \n",
        "    #@tf.function\n",
        "    def step(x, y, training):\n",
        "        with tf.GradientTape() as tape:            \n",
        "            # unlabeled data\n",
        "            x_wk = weak_transformation(x)\n",
        "            outs_wk = model(x_wk, training)  # should this be training or not?\n",
        "            weak_labels = pseudolabel(outs_wk)\n",
        "            weak_labels = threshold_gate(weak_labels, outs_wk, hparams['threshold'])\n",
        "\n",
        "            x_str, choices, bins = cta.augment_batch(x)\n",
        "\n",
        "            outs_str = model(x_str, training)\n",
        "\n",
        "            cta.update_weights_batch(weak_labels, outs_str, choices, bins)\n",
        "            \n",
        "            \n",
        "            #unlabeled_loss = loss_fn(weak_labels, outs_str)\n",
        "            \n",
        "            # labeled data\n",
        "            #outs = model(x, training)\n",
        "            #labeled_loss = loss_fn(y, outs)\n",
        "\n",
        "            #add losses together\n",
        "            #loss = labeled_loss + lambda * unlabeled_loss\n",
        "\n",
        "            r_loss = tf.add_n(model.losses)\n",
        "            outs = model(x, training)\n",
        "            c_loss = loss_fn(y, outs)\n",
        "            loss = c_loss + r_loss\n",
        "\n",
        "        if training:\n",
        "            gradients = tape.gradient(loss, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        accuracy(y, outs)\n",
        "        cls_loss(c_loss)\n",
        "        reg_loss(r_loss)\n",
        "        \n",
        "\n",
        "    training_step = 0\n",
        "    best_validation_acc = 0\n",
        "    epochs = lr_boundaries[-1] // val_interval\n",
        "\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        for x, y in tqdm(ds['train'].take(val_interval), desc=f'epoch {epoch+1}/{epochs}',\n",
        "                         total=val_interval, ncols=100, ascii=True):\n",
        "\n",
        "            training_step += 1\n",
        "            step(x, y, training=True)\n",
        "\n",
        "            if training_step % log_interval == 0:\n",
        "                #with writer.as_default():\n",
        "                    c_loss, r_loss, err = cls_loss.result(), reg_loss.result(), 1-accuracy.result()\n",
        "                    print(f\" c_loss: {c_loss:^6.3f} | r_loss: {r_loss:^6.3f} | err: {err:^6.3f}\", end='\\r')\n",
        "\n",
        "                    tf.summary.scalar('train/error_rate', err, training_step)\n",
        "                    tf.summary.scalar('train/classification_loss', c_loss, training_step)\n",
        "                    tf.summary.scalar('train/regularization_loss', r_loss, training_step)\n",
        "                    tf.summary.scalar('train/learnig_rate', optimizer._decayed_lr('float32'), training_step)\n",
        "                    cls_loss.reset_states()\n",
        "                    reg_loss.reset_states()\n",
        "                    accuracy.reset_states()\n",
        "\n",
        "        for x, y in ds['test']:\n",
        "            step(x, y, training=False)\n",
        "\n",
        "        #with writer.as_default(): TBULATE THE FOLLOWING WHEN UNCOMMENTING!\n",
        "        tf.summary.scalar('test/classification_loss', cls_loss.result(), step=training_step)\n",
        "        tf.summary.scalar('test/error_rate', 1-accuracy.result(), step=training_step)\n",
        "            \n",
        "        if accuracy.result() > best_validation_acc:\n",
        "                best_validation_acc = accuracy.result()\n",
        "                #model.save_weights(os.path.join('saved_models', runid + '.tf'))\n",
        "                \n",
        "        cls_loss.reset_states()\n",
        "        accuracy.reset_states()\n",
        "            \n",
        "    \n",
        "    \n",
        "def cifar_error_test(model, tr_len=20, vd_len=2):\n",
        "\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    optimizer = tf.keras.optimizers.SGD(0.01)\n",
        "\n",
        "    ds = tfds.load('cifar10', as_supervised=True, in_memory=True)\n",
        "    std = tf.reshape((0.2023, 0.1994, 0.2010), shape=(1, 1, 3))\n",
        "    mean= tf.reshape((0.4914, 0.4822, 0.4465), shape=(1, 1, 3))\n",
        "    \n",
        "    def train_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        x = tf.image.random_flip_left_right(x)\n",
        "        x = tf.image.pad_to_bounding_box(x, 4, 4, 40, 40)\n",
        "        x = tf.image.random_crop(x, (32, 32, 3))\n",
        "        x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "    def valid_prep(x, y):\n",
        "        x = tf.cast(x, tf.float32)/255.\n",
        "        x = (x - mean) / std\n",
        "        return x, y\n",
        "\n",
        "    ds['train'] = ds['train'].map(train_prep).batch(5).take(tr_len).prefetch(-1)\n",
        "    ds['test'] = ds['test'].map(valid_prep).batch(5).take(vd_len).prefetch(-1)\n",
        "\n",
        "    accuracy = tf.metrics.SparseCategoricalAccuracy()\n",
        "    cls_loss = tf.metrics.Mean()\n",
        "    reg_loss = tf.metrics.Mean()\n",
        "\n",
        "    #@tf.function\n",
        "    def step(x, y, training):\n",
        "        with tf.GradientTape() as tape:\n",
        "            r_loss = tf.add_n(model.losses)\n",
        "            outs = model(x, training)\n",
        "            c_loss = loss_fn(y, outs)\n",
        "            loss = c_loss + r_loss\n",
        "\n",
        "        if training:\n",
        "            gradients = tape.gradient(loss, model.trainable_weights)\n",
        "            optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "\n",
        "        accuracy(y, outs)\n",
        "        cls_loss(c_loss)\n",
        "        reg_loss(r_loss)\n",
        "        \n",
        "    training_step = 0\n",
        "    for x, y in tqdm(ds['train'], desc=f'test', total=tr_len, ncols=100, ascii=True):\n",
        "\n",
        "        training_step += 1\n",
        "        step(x, y, training=True)\n",
        "        c_loss, r_loss, err = cls_loss.result(), reg_loss.result(), 1-accuracy.result()\n",
        "        print(f\" c_loss: {c_loss:^6.3f} | r_loss: {r_loss:^6.3f} | err: {err:^6.3f}\", end='\\r')\n",
        "\n",
        "    for x, y in ds['test']:\n",
        "        step(x, y, training=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9vH0aDt5Ry",
        "outputId": "9aa336fe-1d37-4788-8b06-9b3c490ce4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "import json\n",
        "\n",
        "#ds = tfds.load('cifar10', as_supervised=True)\n",
        "\n",
        "#tfds.load('cifar10.3@10-label')\n",
        "ds = tf.data.TFRecordDataset('cifar10.3@10-label.tfrecord')\n",
        "\n",
        "with open('cifar10.3@10-label.json', 'r') as myfile:\n",
        "    data=myfile.read()\n",
        "\n",
        "# parse file\n",
        "obj = json.loads(data)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-b132a6755d88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m groups = [('labeled', ds.train_labeled),\n\u001b[0m\u001b[1;32m     16\u001b[0m               \u001b[0;34m(\u001b[0m\u001b[0;34m'unlabeled'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_unlabeled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m               ('test', ds.test.repeat())]\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TFRecordDatasetV2' object has no attribute 'train_labeled'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h06AqVwlXATf"
      },
      "source": [
        "model = WRN_28_2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIpVOZA3V7Wl",
        "outputId": "bcf18e82-5119-4805-8014-224f51608cf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# hyperparams\n",
        "lamda = 1     # proportion of unlabeled loss in total loss\n",
        "eta = 0.03    # learning rate\n",
        "beta = 0.09   # momentum\n",
        "tau = 0.95    # threshold in pseudo-labeling\n",
        "mu = 0.7      # proportion of unlabeled samples in batch\n",
        "B = 64        # number of labeled examples in batch(in training)\n",
        "K = 2 ** 20\n",
        "nesterov = False\n",
        "# weight decay\n",
        "# SGD instead of Adam\n",
        "\n",
        "\n",
        "#CTAugment params\n",
        "cta_classes = 10\n",
        "cta_decay = 0.99\n",
        "cta_depth = 2\n",
        "cta_threshold = 0.8\n",
        "\n",
        "hparams = {'lamda': lamda, 'eta': eta, 'beta': beta, 'tau': tau, 'mu': mu, 'B': B, 'K': K, 'nesterov': False, \n",
        "           'cta_classes': cta_classes, 'cta_decay': cta_decay, 'cta_depth': cta_depth, 'cta_threshold': cta_threshold}\n",
        "\n",
        "training(model, ds_l, ds_u, hparams)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d8a7046d3255>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'training' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bkYlQ3BbM5A"
      },
      "source": [
        "#ds = tfds.load('cifar10', as_supervised=True, in_memory=True)\n",
        "\n",
        "mean = {\n",
        "'cifar10': tf.reshape((0.4914, 0.4822, 0.4465), shape=(1, 1, 3)),\n",
        "'cifar100': tf.reshape((0.5071, 0.4867, 0.4408), shape=(1, 1, 3)),\n",
        "}\n",
        "\n",
        "std = {\n",
        "'cifar10': tf.reshape((0.2023, 0.1994, 0.2010), shape=(1, 1, 3)),\n",
        "'cifar100': tf.reshape((0.2675, 0.2565, 0.2761), shape=(1, 1, 3))\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_ET93aSebHs",
        "outputId": "da6ca4ef-b6d0-4644-a6b2-bfd4f3044dae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        }
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "#ds = tfds.load('cifar10', split=\"train\")\n",
        "\n",
        "#cta = CTAugment(10)\n",
        "#cta.augment_batch(ds.take(4))\n",
        "\n",
        "for raw_record in ds.take(5):\n",
        "  parsed = tf.train.Example.FromString(raw_record.numpy())\n",
        "  #print(parsed)\n",
        "  parsed.features.feature['image']\n",
        "  #image, label = example[\"image\"], example[\"label\"]\n",
        "  print(parsed.features.feature['image'])\n",
        "  #print(parsed.features.feature['label'])\n",
        "\n",
        "#print(np.max(image))\n",
        "\n",
        "#plt.imshow(image)\n",
        "\n",
        "\n",
        "#train_set = {'images': np.frombuffer(train_X.read(), dtype=np.uint8),\n",
        "#                     'labels': np.frombuffer(train_y.read(), dtype=np.uint8) - 1}\n",
        "\n",
        "\n",
        "# Create a description of the features.\n",
        "feature_description = {\n",
        "    'image': tf.io.FixedLenFeature([], tf.uint8, default_value=0),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
        "}\n",
        "\n",
        "def _parse_function(example_proto):\n",
        "  # Parse the input `tf.train.Example` proto using the dictionary above.\n",
        "  return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "#parsed_dataset = ds.map(_parse_function)\n",
        "#parsed_dataset"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bytes_list {\n",
            "  value: \"\\211PNG\\r\\n\\032\\n\\000\\000\\000\\rIHDR\\000\\000\\000 \\000\\000\\000 \\010\\002\\000\\000\\000\\374\\030\\355\\243\\000\\000\\010\\301IDATH\\211-\\326\\307\\216e\\327u\\200\\341\\275\\366\\332\\341\\244\\233\\352\\336\\212\\335\\325E\\213M\\221`K\\362\\310\\200\\000\\333\\320\\213{l\\300\\360\\300\\320@\\006\\3146\\331\\241\\272\\342\\215\\'\\237\\235\\326\\362@\\376_\\342\\373\\241(\\177\\006\\020\\000 \\004$\\301\\200\\022\\244\\2101H\\2314\\306\\017\\037n\\377\\374/\\177|z|\\256\\017\\361\\227\\377ylNcQ\\024]\\327\\n\\001B\\306\\2337k\\224\\331\\375\\227\\027\\301\\306{\\'d0\\332l\\316\\027W7\\325bm\\217\\315is~\\256\\000\\004\\242\\004\\220\\314$\\204T\\032\\021\\331\\tb\\026 d\\333N\\377\\373\\313\\3754M\\323\\000\\336\\005\\\"\\352\\272>\\204\\010B\\256/\\262\\253\\353\\352\\365)!\\346\\332\\370\\365\\225Q8S\\250n\\357.?\\374\\361\\266\\230\\341\\257\\237\\036__w\\312Z\\303LRJ)\\025H\\224\\230XL\\t\\003\\223\\222\\200\\343\\220\\276~\\336\\366]\\217\\2309\\027\\020QJ)\\004\\307\\220\\226\\253\\205\\220i\\273\\333Ji\\277\\373\\335\\305\\367?n\\036\\356\\267\\257/{@\\307\\340\\2111FO\\211p\\266\\270I)R\\212\\002\\004\\010\\231\\342`\\263\\364\\341\\347\\037S\\344q\\362D\\342th\\230T\\014\\354\\\\\\220\\022\\255\\265\\314\\274\\336l\\312*\\177}}\\031\\373\\220\\027\\372\\346v9\\233\\253D\\336\\332\\214\\t\\332\\266{||\\331\\037\\332q\\014*F\\'\\004\\263H)\\021\\'Nq\\274ys\\366\\303\\373\\273\\323~8\\035{JB\\260\\361\\216A&\\301\\220Rbf\\000\\341\\275{y\\232\\352f|\\377\\303\\273\\313\\353\\345\\347/\\037\\313\\352\\273\\213\\213\\315\\247_\\237\\037\\036vR*\\324\\240,L.(\\000\\006\\2312\\213R\\3024F\\001b^V\\017\\367\\217\\373\\343)\\233g>L\\271\\325J*7\\216\\250\\320Gr\\316\\247\\224b\\354\\230\\221\\310\\370\\220\\366\\373\\023\\263\\035\\007Pz8\\325u\\335\\365\\000\\266\\252J\\002\\\"\\002\\225eF[\\2515\\204\\350H&\\0218\\267\\350\\375 \\263df\\252`D\\002\\214|\\276\\\\v}z\\332\\235\\210\\210\\377\\236`\\324x\\177\\377\\312\\\"e\\231\\315\\262:/\\316\\252\\371\\334%A\\002\\255E\\215Z\\205\\210y\\271\\322\\006\\205`\\347\\307\\353\\267\\305\\273\\273r\\265R6O\\325BY\\313\\347\\2539G_\\344\\331\\274\\252v\\207\\243\\367\\004R\\010`J\\021Q\\242\\024D\\221)y?z\\327\\3078I\\024,\\251\\232[ce\\337\\366!$e\\254h\\333\\243\\261&\\313\\364\\305\\371|\\2751c\\333umkM6\\233Y\\246\\260z\\273\\2212\\377\\345\\227/mw\\224X \\\"\\263`f\\224,\\201H$\\342\\240\\021\\254\\321RJc\\2644\\354b\\'\\004\\304\\230\\334\\224\\324\\362L\\247CB\\031$\\312\\256\\355)M\\315\\251\\217\\343\\264\\236\\251\\371R\\243\\202\\331,\\177xi\\352\\246\\026(@$\\220B\\002\\010)\\201\\022\\'R\\222\\204\\004TBB\\252O\\'\\201<[\\225\\203\\357\\275\\013BhD\\304\\337\\377\\341f\\261,\\363\\\\\\013\\221\\016\\273\\027!\\020d^\\332B\\371x\\265\\254n\\3167\\373}\\363\\262\\255\\273\\211\\\\H\\000\\\"\\313\\214\\315\\214\\020\\211)!\\010\\224\\214J\\000\\020\\000\\013$e\\014\\261t\\236\\2471\\372)\\004\\037\\324w\\377p>M\\201\\031\\245\\324\\333\\'S\\315\\026\\211Ll\\332J\\343z^n\\026\\253}\\035\\230\\033\\000%$H`\\251\\004H&&\\000B\\004!\\230(d\\231>\\277\\332$\\244v\\030O\\317\\275\\266\\3454\\211\\024\\002\\002*\\005\\221xd\\200\\263\\213\\253\\371\\352\\373\\256\\356\\307\\272)\\213t^U\\207\\356X\\235o\\002\\320\\340{[\\350\\\\\\010\\245\\344\\254\\314\\210p\\030G\\001\\222\\201X\\304(\\034i\\316\\026\\222\\021\\234\\020\\203\\363D\\022\\245\\220\\240\\265\\262\\370\\363\\037\\256\\265\\321,\\005\\213\\224\\222\\010\\223[\\026\\371z^\\256\\227\\363\\254X\\004V\\316\\007%\\001\\242\\253r\\\\\\314\\262Y\\221q\\010\\344\\274\\210\\001bbf\\0012\\t\\031\\005\\0273ML\\022\\320ZK\\221\\222g)\\244B\\324\\332\\330\\251m\\333\\261\\321:\\267\\332\\030cfE\\271\\250f\\237>\\277\\276\\276\\354P\\304\\017\\337\\335\\2527!\\\"\\007%\\216\\207\\266\\313&u\\265\\236\\006O\\216N\\343\\364p8\\366\\211%\\033A\\020]\\014.\\244\\030\\335\\224\\004\\203\\322V\\225\\345Lk\\343zG\\240\\2545J\\251L\\033\\001\\362\\343\\247/\\177\\375\\257\\337\\334@\\327\\253\\342\\244\\305_\\376\\351O\\267\\357\\337y%c\\344\\030\\010\\225\\206\\224\\204\\240\\227S\\373\\267\\317\\337\\376\\343\\257\\377\\275m\\232\\256\\366\\300R\\262\\234\\246\\020]T\\250\\001XI\\324F\\031\\005\\312\\273)\\253\\224\\315\\354j\\266l\\016\\365\\327\\207\\307\\343\\251\\226Q\\305B\\226V_mVgE\\036\\025 \\252q\\234v\\273\\235\\2612\\361$\\374\\361\\247w\\213\\333\\353?\\377\\333\\277\\377\\347\\267\\323\\024\\223tD\\222$\\nE)N\\323\\200?\\374tC!\\026\\332rLLAi\\231\\\"\\215\\375\\024#MC@\\346\\325,\\377\\361w\\357no.\\2545\\000B\\2444\\r\\375\\363\\3437\\243U\\214|:4C;\\235/V?\\375\\370sO\\352\\313\\227o\\323\\340\\211\\244 \\260\\271fA\\312\\273\\341|9/\\263\\334j9\\371\\336(\\025\\243\\213\\344\\362\\322\\334\\\\.\\335\\251\\335\\254\\253$\\302\\323~K\\310E\\231WU\\005\\n\\363\\252`i\\267\\333\\366\\365\\305\\327m\\367\\361\\267\\347\\357\\377\\361OB0S \\366)\\002\\200\\001b\\221H%\\362uw\\362~T #\\3210LJ)\\2451q\\252J\\\\\\310r\\261\\310\\353\\256\\376\\364-\\261\\342+{\\225K\\321\\014\\303\\363n\\377\\272\\377\\364\\365\\276\\256\\367}\\357\\374)\\324\\177\\333\\275\\356\\207\\200\\212\\225JLJI\\355\\\\\\237(\\252\\310\\262\\035\\034b6\\3050\\016.Q*\\313J\\010\\026\\240\\244\\262\\201B\\335\\215\\271Q\\304\\375\\354\\330\\227\\325(D\\363\\272=|{x\\371\\370\\353\\327}\\023\\375@\\375\\344\\344\\\\\\035\\233:H]\\314\\212\\220bY\\315\\334\\010\\343HL\\254\\022cJ \\321t\\355\\330v\\243\\2656Dn\\332\\346\\362\\342rq\\263<\\360\\323\\330\\367hL{h\\245\\331\\365SP\\nO\\247z\\273o\\034\\201O\\354\\211A\\233\\345f=\\251d\\224\\266\\231A\\255\\333&DN\\000\\300\\314*\\323\\032\\210%q}\\330\\327u3\\233\\315P\\010dQf\\331\\365\\365\\345\\305f\\361\\370\\355q\\367\\274\\355\\306\\261\\377\\372p\\377\\262\\225\\000\\3434\\305\\030\\225\\316\\205\\3464\\005i\\264P\\246\\230\\353!\\005\\202D\\220\\232\\276\\031G\\022\\224\\230H}\\377\\366\\006\\205,\\363\\274~y\\312\\021\\020UeT6\\257\\226E6_\\346\\221\\360\\214\\316\\272\\251\\323E\\346\\003m\\367\\247\\020\\274\\265YV\\315\\001U\\252G\\237H\\242\\010\\314\\0061\\306\\201B\\324\\231]\\254\\346\\343pJ)!\\242\\022~\\254f\\363\\367woV\\271q\\316\\245\\224RJ\\233\\315\\006\\021\\273\\261\\351\\303p\\375\\366\\262k\\333\\375\\353\\341\\352\\352\\215\\327\\331\\344&\\255\\265\\261\\226C\\014Lh4Z\\235\\227eV\\345}\\350\\023qY\\226Lv\\350b\\353i}\\266R\\326\\252\\340\\247\\340\\246\\\"\\267\\263\\252\\330l6E\\226sL\\010\\260\\037\\272C\\333\\0306\\322s.Uf\\360\\354|>\\371L\\242N\\002\\232\\375\\241\\\\V\\016\\307\\252\\314!:E9\\nC,\\272z<\\036kD\\206B\\210\\202\\325\\371\\305\\305\\335\\233\\333*/^\\236\\236\\247\\340\\002\\223\\2202\\222\\337\\\\^\\341P\\006\\222\\245\\315V\\363ee\\213\\233\\273\\333\\345\\330\\266\\375\\350BR6\\377\\352F\\023\\343@d\\215dA]\\335\\270ab\\200\\311\\017\\ne\\236Y\\233\\347\\306\\242b\\0016/\\264\\315n\\357\\356\\306\\024\\\\\\014\\215\\233\\2541\\021%!.\\317V\\006\\325|\\271h\\216\\365\\335\\333\\353+Z\\017\\3434\\206\\350\\003\\365\\373\\335k\\327\\377\\235\\350\\020&\\237$\\305\\024R\\314\\254\\225\\322*m\\262\\304YaUQ-F\\037\\214\\316\\316\\327\\347%\\n\\237br^\\n8u\\203\\363~\\271ZI!\\030 1K`\\031]\\216Pf\\2452\\331\\313\\323\\363o\\037\\177\\263\\231\\251\\362\\342\\365\\270\\317\\346\\363vj]?\\346\\332PJ!N!\\006\\253@\\375\\363\\277\\376%\\371`PUE\\021\\200\\233\\266\\213\\340\\014*H\\300B\\324m\\003\\314u\\337\\235\\332z\\273\\335\\201\\210\\022\\265k\\372j\\276j\\333\\266\\254\\212w\\227\\327\\373\\355\\316Xe\\255.l\\226i\\013\\022\\232\\246\\3153\\213LCS\\313j6\\313\\362\\242,+\\223\\345\\n\\224\\006T\\002E\\344\\322\\346Z\\233\\246m\\017\\307\\243\\220Pw\\355\\375\\303S\\210\\254M\\216:\\377\\370\\353\\347\\347\\347\\227\\037~\\377~\\271ZNnL1*\\224UY\\226e\\311\\211\\200\\231\\211\\nk\\312,S\\300\\220e\\271\\222H\\377?#H\\250\\246a\\364\\336=>=\\357N\\373\\322\\346g\\253\\263\\361\\242\\3276\\367\\002[\\027@\\252oOO\\313\\263\\263\\313\\253K\\364q\\275\\\\j\\253/\\257\\257v\\273\\34309\\240,\\204`\\214Y\\257\\327\\3030\\376\\037\\261\\222\\302Hs\\331\\335Q\\000\\000\\000\\000IEND\\256B`\\202\"\n",
            "}\n",
            "\n",
            "bytes_list {\n",
            "  value: \"\\211PNG\\r\\n\\032\\n\\000\\000\\000\\rIHDR\\000\\000\\000 \\000\\000\\000 \\010\\002\\000\\000\\000\\374\\030\\355\\243\\000\\000\\t`IDATH\\211\\005\\301\\331\\216\\034W\\031\\000\\340\\377lu\\352\\324\\326U\\325\\335\\323=\\213g\\261=\\261\\035\\033%\\\"\\\"\\n\\204\\300\\r7H\\274\\001o\\3053p\\303]\\270A\\342\\002\\210D\\002\\221\\200$&\\006\\354\\304\\343\\231\\361\\214=K\\357\\265\\237:\\033\\337\\207~\\375\\253\\207u\\267&1\\326\\270\\3526}\\214\\007\\311\\326\\340|u\\211j4\\235\\356\\235\\236\\334^~\\267\\361\\rB\\332\\246cl\\261\\241\\036\\341\\234\\245\\336`v\\275J\\246\\001\\020\\3431n\\264\\303\\230\\021J,\\265\\010ck\\r\\347\\276\\020~\\265i)%\\230\\020\\354\\234\\353Zm\\301J\\326\\367N\\351\\306\\354o\\335;=\\271\\276~\\275N\\005\\3576=e\\030\\020`\\002\\\"\\360\\002!l\\357,\\002\\214X\\333\\351\\266)=\\346s\\316\\234C\\030S\\0076\\n\\343,\\317\\2430\\250DK1\\000\\301\\304 \\351Qj\\tr>\\254\\353\\315\\376d\\257\\230\\351\\263\\227kj1\\341\\340a\\354\\220\\355\\225\\3659\\nB>\\312\\263\\371\\333\\r\\027B)\\267X\\324\\030\\203\\321=\\347m\\232\\306\\324\\2220\\n\\363|D\\010i\\233Vv\\222b\\2040B\\026;\\217\\260V\\201cNPA\\225\\177\\363\\366\\332i\\202\\220\\363)PNjm\\235\\003\\356\\3230\\016,\\030\\345z\\203\\\\\\335\\312A\\032Eq\\330K\\275\\\\\\254\\252\\246a@\\2030B\\010+\\245\\333\\272\\252\\213\\226*\\251\\234\\005m\\254\\005\\243\\215\\213\\303H\\350\\340\\325\\263\\327\\313\\271\\332\\335N\\372\\272\\340\\236\\363\\030\\353*\\303\\270\\025\\201O\\010\\221\\272\\263\\030\\210O\\005\\343\\334\\'a$\\2646\\016\\240(JP\\252m\\333\\246i\\265\\326uYy\\304\\'\\307\\023\\201(\\225\\270\\351\\265\\006\\354\\205Q|\\376\\2377\\365U\\275\\331\\350\\321\\230\\013\\337R\\244\\215u\\312\\032\\036@\\222\\305\\236\\317\\001\\014\\242\\2140\\356\\234\\365\\005\\003\\354\\254q\\303\\321\\020\\023\\2140v\\316:\\347\\234s`\\241\\251\\024I@\\366F\\203o-E\\000\\336\\374\\262\\\\]\\224H\\002c\\310\\017\\261\\037bk\\265\\003\\007\\304Q\\216\\362a\\026\\206\\311`\\020*\\007a\\222\\004\\202al\\225\\356\\215\\263\\030!\\343,\\245Tk\\235\\347\\271\\020\\302j}\\363f\\216\\327\\313\\376\\342\\365\\272\\330(DqY\\264\\257\\236\\256\\3735X\\013\\241\\217\\264R\\016Q\\005\\026\\250\\023\\0021\\017\\033\\013R\\332\\343\\343w\\3028\\240\\034e\\243(\\313#\\347\\014\\245 B\\316\\030A\\200\\2430\\311\\322\\034cJ\\2002\\202\\361 \\t\\363<3\\006\\361\\200\\031e\\002G\\023\\026$\\261\\337w\\256.\\215\\266\\2443XZ\\013\\304Q\\212\\ta\\306\\200\\010\\304 Mx\\300\\212j\\201\\220\\036o\\345\\204\\222\\321(K\\006!&\\204R\\n\\2000\\302m+\\323,#Ov\\262t\\230\\256\\2725\\212\\010\\005\\037*\\223\\304\\021\\010W5\\275\\005\\000\\004\\0040h\\203\\211C\\2240/D\\230\\215\\307q\\247:\\356y\\243,\\277\\263\\177\\310x`\\255\\313\\263L\\365\\022;\\312\\203 I\\263\\252,@)\\0373\\034\\205\\036q=\\367\\210\\254\\255C\\230M\\260\\177\\310\\375\\275\\001\\233\\206b\\310\\214\\352\\003K]\\007\\306 c\\361b\\261\\016\\205\\220\\235tR\\332F}\\370\\376\\317\\343x\\267\\354\\300\\202\\267.*\\260&\\211\\202M\\333\\2618\\351\\272v\\3403A1\\305\\014i\\320q\\3545\\240<\\306&w\\357dY\\336\\031;\\232\\336i\\326\\213\\327\\337\\2356\\306\\364\\010<\\214;i\\214\\226;\\273\\323\\262*\\215\\001\\255\\014&\\336\\263\\377\\274\\030O\\207\\246\\223\\310\\231|8\\2516\\375\\316\\336p\\220fi\\222\\220\\256\\263\\226\\322J\\226a\\032c\\206\\234F\\330a\\327\\243\\253\\363\\353\\326\\230(\\033\\355\\335\\275\\007\\214>\\377\\357\\367@\\200)P\\332(\\205\\257\\256\\027\\203\\214n\\357\\356bLV\\325\\312h\\225\\010\\336\\206\\221s\\210R6\\334\\n:\\214\\263$]\\005\\221\\301\\336\\325bI+Y\\307\\376\\300\\202\\343\\234\\265e;\\233\\335\\202\\205u\\345\\222q\\035\\206\\336\\321\\273\\3676\\256={z\\332Hk\\265\\343\\234\\207Q\\034\\0048\\nC!\\274^\\225\\223qpuyNi\\200\\231\\030\\215w{M\\377\\374\\207?z\\037#F<\\203\\335\\325\\242 \\307\\207\\201\\027P\\313\\240W\\246ZH\\242\\361z\\2566K\\325\\326\\23522\\036\\205\\333G{\\263\\353y\\263l\\tF\\007\\007\\007\\237\\374\\354g\\240j\\260\\335h\\230\\214\\262$\\026\\341z\\265!\\314W\\232\\3349x\\360\\371\\227O?\\373\\313\\027\\241\\207\\007\\234\\266\\262\\377\\366\\371+\\362\\223\\017\\357\\000\\305\\300\\320r\\331\\232\\026q\\344U\\253FpB\\265\\235\\317k?\\302\\333\\007\\223q\\276u\\372\\342\\334\\247\\374\\375\\367>\\370\\321G\\037\\r8\\214\\322\\240.VF\\313\\307\\017\\337;<|GY\\327J\\333v\\350\\267\\277\\373\\324\\366\\335\\301t\\354St~\\376\\326!\\240\\016\\001\\245\\264\\327\\212 \\214<\\250\\346\\215\\360Q\\300\\005\\264]a\\364\\315\\351\\365\\341\\375\\335\\007\\217~p\\366\\340D\\255\\344\\376\\341\\321\\375\\007\\217\\253K\\210cT\\224\\263\\272\\252\\253\\252\\357\\035\\363\\203\\300\\027\\362\\277\\317_,\\027\\313i\\026\\371\\224\\\\\\335\\314\\256g\\213\\373\\307wq\\024GR\\366]\\255\\206Y\\302\\005\\265\\326\\245\\203\\230Q\\n\\306\\216S*\\300./fuY~\\360\\343\\037\\\"\\202\\266&;\\371p\\'\\312\\266\\375h\\342\\007\\223\\361\\366;\\371\\364x\\274{oY\\224\\3718\\275xs\\301\\030\\036\\016\\242b\\275Z\\254\\313\\371\\246\\363\\303\\004\\007\\\"@\\200\\301\\220@\\004^\\340\\213\\000\\007\\201\\2170\\020\\017\\'\\203\\350\\007\\217\\3371\\215:;;\\2112A(\\241\\214kG\\017\\036\\177\\344\\347G\\331\\336\\223\\375w?\\331\\177\\370\\341\\326\\356]\\352\\363\\007\\217\\216\\017\\017\\247\\010\\331\\275\\351\\250\\255\\252V\\231E\\243?\\373\\362\\337t1[r\\317\\227\\255[\\314+ \\306a\\255\\215.\\253Jp\\227m\\r\\3030\\376\\356\\344z\\341\\272\\361n>\\232\\014)\\365\\010\\023\\330\\317\\323\\235\\001\\200Q=\\324M_wVjSV\\353\\343\\343;\\371 \\346\\024\\267\\004\\255\\326e\\325\\233\\346\\246\\240\\233E\\021\\017\\\"\\244u[TA\\346k\\200Ni\\317gQ,6E}=\\177y\\363f\\001\\235\\277Y\\316\\000k\\331#\\217\\t\\353\\260\\265\\024!\\266)J\\344\\020\\000\\025\\276\\230\\317\\256\\222\\320{\\362\\360\\256\\323\\332 \\273wo\\212\\307\\362\\325\\313+\\212\\r\\222e\\303\\211CZN\\362\\351\\374\\355f\\265n\\366\\306\\271\\240\\301\\365\\233Y\\234\\010\\216)V\\250\\272YT\\265\\332\\024\\306Y\\213\\261!\\210he\\301Z\\323\\367MY\\311\\252\\255\\3739\\',&\\256\\227\\2723\\np\\277\\177$vw\\357\\323(\\212\\313r\\005\\310\\265\\225\\n\\205\\010D\\220\\t!ky\\371\\352<\\212\\\"\\002~\\024\\364E\\253\\327\\267\\215\\266\\356\\346\\372\\262.o\\243x\\3279\\213\\034\\302\\316\\226e\\261\\230\\317\\254\\0010\\320\\264\\215Q\\2252Vj\\364\\354\\313K\\217\\303\\223\\'\\007\\344\\303\\'{J\\351\\266\\221\\332j\\013\\036\\302\\376z^\\312J\\366\\255U\\312Hit\\357\\352FG\\211\\037\\006\\276\\321\\336\\243\\307G\\334\\013\\271/T\\257\\232\\272\\221]ss\\365z\\020\\363a:x\\366\\364\\333\\266X\\027\\235:\\177[\\2004\\251Ge\\333Q\\245\\0248b\\r\\211\\303d9\\333X\\027\\277>[\\017\\004\\355{\\227D\\\\Im\\214\\355;=\\277\\252\\246\\223\\354\\374\\354\\345\\253\\223\\347\\016\\304\\021\\\"\\2527V\\033\\214\\314\\305\\353\\263,aw\\017v\\372\\316`\\000\\r\\270\\250\\245\\247Q\\350\\260jz\\332Km\\014 \\360<\\217\\337\\314o1\\221\\024\\203\\263\\220\\346\\202\\020\\260\\n\\005\\204;\\344\\300(\\217\\260\\305l\\366\\315W\\337\\216\\307\\3676\\253\\245V\\3329X-g\\247\\247\\247\\277\\371\\364\\367\\277\\374\\305O\\353R\\022$\\244\\252\\215\\205\\200b\\201\\211\\003\\240\\010\\021\\243U\\030$u\\327\\326\\225D\\004\\013\\301\\037\\034\\355D\\231\\327\\324\\315\\362v\\265Z\\324q\\304\\342\\024y\\214\\372\\036\\373\\333\\347_?x\\360>#\\004#\\334v\\355\\253\\223\\357\\377\\374\\247\\277Te\\371\\315W_\\037\\355MB1^\\257\\026\\340 \\024h2\\n.V\\005\\355Z]\\226\\r\\243\\366v\\276\\244\\204\\000\\306\\273\\373\\223,\\217\\274X\\367JQ\\246\\006\\t\\036\\216\\2230%\\214\\222^\\313\\253\\223\\313/\\376\\372\\371z9\\037\\217GMS\\377\\375o\\237cd\\037\\036\\037pl\\203\\300_\\315\\024!>%\\010QK\\004\\036\\362\\214\\366\\322\\\" eY\\206\\2418\\230\\034\\266\\262\\247\\310\\004!\\005\\256\\363Q\\314\\020v\\322%\\203X\\244\\\\*\\325\\333n\\271\\251\\377\\365\\317\\1775U1\\336\\312V\\253\\305\\365\\3655\\002srr\\361\\350x\\032F\\376\\331\\371\\\"\\tC\\206\\260\\2370\\022\\007}\\241(\\245\\274i\\326\\236G\\267w&\\\"I\\274\\246%H9\\327We\\351\\014\\034\\354\\357_\\235\\337\\020\\302O^\\336\\016\\367\\266\\266\\266\\223\\371\\252;;\\273H\\\"\\301\\230k\\233\\346\\325\\311\\351|Vo\\345I\\226\\306\\233r\\306c\\'4\\366\\010\\245A\\334`|q\\273\\242M\\335{\\036\\037\\215\\006A(\\234\\323\\306\\312\\355\\355\\341\\325\\305\\2117\\340i\\234\\337\\\\-\\336^\\316\\302D\\337\\314k1\\324\\255\\252\\322\\021\\237\\004;q\\024\\275\\370\\337\\367\\276O\\272\\256\\317\\322p\\377\\316\\226\\357\\263^U\\235\\253\\254\\3668\\361k\\211T\\245%xT\\004~:\\014D\\310\\010\\303u\\3232\\n\\310A]k\\236D\\317\\377w\\332mZc\\314\\200\\222A\\034\\271^uE\\313\\243\\240\\325\\305\\213\\177\\274\\0148>:\\332\\031M\\263\\275\\355\\021\\353{d\\315\\252*\\263,\\2768_\\250\\300\\372\\333|\\377\\336\\341\\243\\217\\323\\377\\003\\221\\017u/\\214ZER\\000\\000\\000\\000IEND\\256B`\\202\"\n",
            "}\n",
            "\n",
            "bytes_list {\n",
            "  value: \"\\211PNG\\r\\n\\032\\n\\000\\000\\000\\rIHDR\\000\\000\\000 \\000\\000\\000 \\010\\002\\000\\000\\000\\374\\030\\355\\243\\000\\000\\t\\265IDATH\\211\\005\\301Ks[\\327a\\000\\340\\363\\276o\\\\\\000\\004@\\220\\242D=HIvd;\\256\\023\\331m\\'\\343.<i\\332l:Y%3\\315:\\333\\376\\207\\376\\217.\\272l\\2473\\335t\\334\\2318\\323\\244M\\223\\261\\334$zR\\242,\\212\\\"EB\\000A\\000\\027\\367u\\336\\347\\364\\373\\340\\217\\377\\361\\037\\\"B\\000\\004c\\020\\310\\212\\317\\253\\312\\246\\314E4\\245x3H\\200\\007\\246\\256N\\276\\235O\\332\\266\\277\\335\\323\\002\\364\\207\\033AD\\010e\\216+l\\001\\360:\\210#\\340\\240W\\246\\023\\305,\\242\\022#\\017\\001\\304V\\352\\246lj\\342\\200\\347F\\031m>\\357\\r\\220\\241uo\\360\\266Z~+\\312\\250\\001\\031/U\\255\\372!<\\253*\\343\\364|\\261\\344\\032\\2418\\210=eD\\004\\016E\\230\\3444\\341\\316E,nE\\203\\t\\366\\020z\\350@\\214j)KQ:\\350\\210VJ\\033\\235Y\\266\\031\\245;qf \\272\\023&{\\226\\313\\213\\371\\243G\\277\\r\\302|\\347\\326\\215\\033\\243\\215\\371z% \\240\\004\\000\\243\\ta\\022+\\3364I\\332\\373\\213\\217~@\\202X\\031s:9_\\272\\232k\\356\\010\\022Vs\\003*i\\003\\014\\211j\\205\\001\\340z\\332\\311\\201{\\361\\3629\\216\\323 \\035f\\200\\234_V\\357\\032\\365\\301fWj\\231\\304\\031ij\\0028\\303\\214!\\027SLB\\366\\341\\235{\\237\\335\\371\\356\\0077\\336\\017\\302\\220ky<9\\377\\3457\\277\\177yx\\354\\363\\210\\003\\031 \\202\\241\\007\\300\\023\\002 \\262\\350n\\336\\035\\247\\350eqz\\357\\306\\375\\265\\201\\337<}\\365z\\261\\2620\\014\\210\\255\\324<\\035o$\\234@Hy\\3212\\327\\331\\300\\354\\376\\355\\357\\376\\350\\363/F\\335\\276s\\326[\\027\\320\\370\\243\\375\\375\\220\\322\\243\\263\\323\\347\\2137\\226z\\247LdM\\'N\\t&\\330*qr\\362&\\237S\\'\\371\\344\\335\\242\\305Nha\\224\\353u\\272\\300\\311\\341\\265\\23595Y\\227).\\024\\344\\306\\312\\204\\261\\217\\367\\336\\333H\\273\\306\\030\\210 \\302\\310{\\000\\254\\275\\276\\275\\375\\235\\033\\373\\217~\\371\\310\\305X#\\355!\\221\\2535\\336\\373\\301\\367\\210w\\213\\027\\247\\261\\366\\233Y\\362\\345\\203\\203\\257\\036\\277\\2742H\\317\\226\\213e]oe\\301\\356\\355\\367^\\025\\005\\312#\\217M\\335\\024I\\024\\374\\350\\317\\277\\370\\344\\336\\307a\\030@\\010!\\200\\000B\\343\\274P\\266^\\027Y\\332\\341\\334h\\2534\\254\\245\\226m+P\\342\\3200\\352\\374\\335\\017\\277X\\241\\270\\304\\335\\333\\303d\\334\\307\\037\\335\\272~e\\243w2\\235\\355\\334\\270\\275\\271\\265\\247<\\231\\255\\027B\\251~\\267\\377\\351\\376\\207\\237\\354\\335c\\2049\\347\\000\\000\\000\\000\\007 \\227f\\265n\\377\\360\\340A\\017\\302_\\374\\344\\357\\177\\376\\327?\\017,\\223\\272\\016\\002D\\272\\010\\n)*\\347\\377\\373\\360xz\\365\\312O>\\375\\313]k\\tD\\037\\\\\\277v\\362n\\352;\\303\\233w\\276\\267_\\254\\336\\276\\370/I\\301\\376\\225\\353\\357m]\\247\\000b\\210\\254q\\200z\\010\\240\\026\\216ss\\261X\\375\\3527\\277\\247a\\306J\\223\\371\\340o?\\371\\354\\353\\351\\023+\\034\\322\\262t\\246]\\255\\327,`\\277yz\\360o\\177z5i\\354d1\\357\\'\\364\\356\\356\\356\\357\\036?/\\204\\206-\\006S\\033\\0242\\250\\332~\\220u\\263\\334+\\343\\265u\\332\\031\\351x#\\275vO\\237<~\\374\\374pQ\\252\\311r\\371zr\\270\\225w{a\\2020 ,#\\266\\026\\233\\343\\315_\\374\\354\\247\\377\\364/\\377|t~\\324\\317\\243<\\216\\036==y\\374fj\\021z\\371\\342\\350\\331\\301\\233\\352\\244\\376\\370j\\374\\376\\200\\336\\350\\017\\255\\346\\032@D\\003%\\001\\364\\310\\031\\260\\270\\230\\377\\317W\\377\\031`g\\225i\\201=^\\237P\\353k\\316\\2655\\370\\317\\376\\352ca\\364 \\035\\336\\036\\357\\016\\273\\024\\000\\355\\0019\\237\\227\\277~zx\\321\\032\\350I\\020\\206/^\\035\\334\\335NG\\030\\334\\274zm\\264}\\305YO0\\262V\\033\\353\\234\\361m\\305\\277\\374\\352W\\277\\375\\337_\\307!UJ\\255\\265\\020\\261\\\\\\230\\262\\225-\\243\\004_\\373\\374\\256\\361\\006Y\\337\\256e7\\315\\021\\300\\215\\362\\317^\\237\\277\\275(\\240\\307\\001\\rWU\\t\\233\\371\\030\\213\\246j\\267wv\\243$\\201\\020\\205!\\363\\316\\001D\\265u\\223\\363\\351\\277\\376\\307\\227\\177|\\366\\244\\227w\\244\\020\\337\\316\\246`h=R\\\\\\2538\\216\\321\\254*\\023\\212=\\021+ \\010\\3157\\373;o\\'\\363\\227o&F#\\335J\\336\\362\\323\\311D\\210\\372l\\272\\020Z\\225\\325\\372\\344\\370u\\271\\274\\254\\212%o\\312\\246./\\347\\363\\327\\307Gg\\323i\\321*\\r\\310\\265\\235\\035\\354AU.\\274n \\\"\\016\\304\\004[@\\010^\\253&\\352x\\200\\300\\321\\331\\344\\017\\207/9\\227\\020\\020\\253\\224\\r\\021\\013B\\255U\\020\\005W\\372\\211\\252Wm\\300\\252\\345\\\"Ic\\250Z\\030\\350\\207\\217\\236\\035\\275>\\253\\252e\\034\\006{\\267\\356\\334\\274y\\227\\364\\372\\347\\364uB\\231\\366\\216+I\\206\\375xi5\\364x\\303V\\363j\\366\\340\\340\\240\\222\\032\\001\\347\\024\\307\\030f\\235\\010b\\224b6\\314\\350(\\301)R\\252]\\254W4\\337\\310\\232B\\307\\231=x\\370M\\323\\312\\010\\352Q\\'\\374\\364\\223\\357\\337\\276ykT/\\246G\\323\\326y\\347\\264\\264\\227\\004C\\344`\\200\\023V\\330\\205_*)$r\\010\\010\\005\\241\\243a\\314\\\"\\306\\233\\272\\233\\262<\\241\\316\\032k\\2142\\215\\022\\262X\\\\\\nk\\347\\263\\242]]\\000\\325\\356\\346\\360\\352h\\274=\\030mn_\\013E\\256\\217\\351\\242Z\\361v\\345\\240!e\\253\\322\\230HQ\\277\\323\\234\\0107\\312HB\\275\\0171\\245\\3101T\\265\\r\\326\\274\\023%i\\'S\\336y\\251\\222\\254\\203\\010\\223BH)f\\357\\246\\221\\223\\335<\\304!F\\3718\\240$H\\272)\\363J\\370\\351lF\\230\\267\\236\\020\\r\\364\\345\\372\\242Q0\\212\\002\\205\\352Qd>\\335\\333x3\\201\\300\\252J\\301\\265h\\t\\301\\210P\\022%\\210\\200VJ\\343$Rm\\000\\263\\030\\303\\004\\350\\335\\255~\\257\\233\\227\\247\\027\\220E\\204\\020\\306(\\246A@\\030\\306H\\033k\\255%\\306\\003m \\204x\\220FM\\323\\356\\357m\\337O\\362\\207O\\016g\\027\\263\\311\\245\\000\\312[\\210+\\241\\032c)%\\205\\261\\266li\\027nG\\311f7\\306\\315Ry\\224\\344\\0356\\253=\\013\\001pF\\2538\\r\\372\\235\\014L\\re\\304\\003B\\224q\\016\\200\\230\\005Z\\310i\\335&=p\\1774\\370p\\2678\\3016b\\025\\251\\325\\254\\024\\227m=o\\343\\004\\305Km\\3438Ci\\326X\\357\\t\\355\\016r\\2132\\003<\\300^C\\010\\220Vm\\023e\\331\\2707\\\\\\317\\252\\321\\3468\\357\\217\\210\\326\\016B\\357\\255-\\327\\362b)\\370\\352\\365\\337\\214\\267o\\216\\006\\303 \\334\\032\\267\\366\\370\\330a\\327\\326m%k\\032\\263(Mz\\203a\\330\\313f\\272\\3158\\333\\212\\322\\260\\277S5-\\\"X\\233Vk)D\\023\\361x\\2741\\372\\316\\336\\256\\207\\260\\277\\321!\\224\\004\\020\\310\\246\\341\\274\\221M\\353=\\325k\\343\\257\\347\\035f[\\241}Ha/\\211bJ\\302$dY\\312\\202$\\313\\273\\225\\267G\\305IY\\343\\037\\357\\3543\\200\\t\\016\\3430\\236\\257V\\353\\242\\334\\330\\344F\\032\\014\\250\\305\\250\\345\\345\\362\\365S\\264\\021\\020\\310[.t\\2673\\330\\036\\21767{\\000ac\\335\\351\\374\\342\\305r\\\"\\003\\300\\010\\334\\336\\314\\243N\\3320\\322\\006\\260\\202\\362h\\371n&\\253o\\212\\311\\304{\\017\\200l\\312\\215\\254\\007\\200\\277\\234O\\rW\\234K\\315\\335B\\242R\\372\\313\\345\\232\\324\\355\\302\\\"OY\\230\\2048\\245\\0148\\031B\\330V\\315Q\\325>\\3666\\356&=\\257\\2234\\224IOF\\201\\002\\355\\272\\325A\\024\\273\\230\\236\\316\\325\\327\\213\\371\\325xd\\252b3\\317\\367o\\335*\\252\\251QJkSU\\325\\274XZ^0\\253qzw\\253\\005\\032\\341\\300Y\\013\\010\\202N\\177\\200\\303woO^\\310\\366\\271\\261\\003\\032\\014\\035\\033_\\335\\005\\243qa\\032.+aA\\255|\\261.1 +.\\244\\024)\\001\\320\\264[\\303\\241F H\\273\\235\\336h\\321\\026O\\317^d\\021a8\\304\\275\\017\\367<\\006\\201#\\336Y\\203\\001/\\326\\327\\312F\\003|\\216\\300\\211\\3229\\362\\254\\261Q>x\\262:\\233\\026\\013!tY5\\027\\353F\\324\\\" h^\\\\\\036\\234N\\014&{\\203\\3018J\\010f\\215&qg\\200\\202\\244\\224\\213\\323\\267\\257\\264f\\310\\000\\000-M\\003\\226\\307\\231W\\222 \\332\\357\\217\\257\\335z_\\\",\\233f\\305\\2133Y=<:\\376\\323\\363\\303\\323\\323\\251,5\\344\\272)\\346\\002\\212V\\210\\345e)q\\364\\273\\311b\\201X\\030\\304\\325\\305\\264\\250\\252eYT5\\337\\212nFh\\333[H\\356\\0147\\244V\\227U\\355\\255I\\\"p\\377\\332\\315\\255l\\360\\307w\\263\\311\\272b\\206D0\\204\\035R\\032\\021\\007\\330[O\\200\\347\\326\\032\\347\\004\\227@\\201\\010\\206]LY\\024=]\\316n\\030\\275\\226\\315\\361\\342\\014m\\014\\217W\\263\\203\\3237Q\\3363\\312\\023\\354H\\333\\360\\313\\025\\337\\331\\332\\332\\312p\\207\\220\\177?x\\374d\\276\\222\\235$\\357o\\264H\\022\\000\\3230\\351B_s\\243!0\\010 Ouex`\\206I\\266\\252\\226\\276\\256\\036\\362\\352\\373\\357\\337\\261q\\362\\365\\263\\247\\377\\367\\346\\234$x\\256\\212\\265V\\332\\031tV\\361U+0t8v,\\211\\037\\\\\\234?25\\357\\304\\2001\\324\\t.\\2158Sb\\220\\014o_\\331\\227\\020+\\214\\254\\367\\004\\001,,\\340\\246v\\306F\\224\\013n\\021\\2319\\347\\243N\\023\\261\\363\\325\\341\\361\\333g\\001e\\246\\025FH|\\375\\263{\\335$\\301\\024]VKk\\26102&\\004\\031\\'\\215\\351\\304\\271i\\225\\361\\034`\\024fQ\\222P\\316\\033m\\315\\336\\235\\367\\214\\003\\312\\010\\347\\314\\260\\337\\307\\224F\\243\\3360O+imD\\266\\262\\372R9\\245t\\275n\\206Wv\\376\\037U6.D\\377\\314i\\337\\000\\000\\000\\000IEND\\256B`\\202\"\n",
            "}\n",
            "\n",
            "bytes_list {\n",
            "  value: \"\\211PNG\\r\\n\\032\\n\\000\\000\\000\\rIHDR\\000\\000\\000 \\000\\000\\000 \\010\\002\\000\\000\\000\\374\\030\\355\\243\\000\\000\\t1IDATH\\211-\\322\\331\\216\\\\\\327u\\200\\341\\265\\2073\\0175\\365P=\\260\\273)Q\\022i\\213\\244D\\300\\212\\241\\030Fd1\\310Un\\234w\\310\\225\\237*/\\220\\213\\\\9\\201a#0\\225\\010R\\\"J\\244\\030\\211\\022\\305&\\273\\253\\331\\325]s\\3259g\\237\\275\\367Z+\\027\\366\\023\\374\\300\\207_\\374\\366\\227\\267W\\241\\216\\263\\270\\256j\\035\\206\\016uk\\032D\\007\\004i\\034\\001H\\0220\\350\\026\\210\\350\\255\\363\\350\\035\\242\\224\\322#0\\362\\242q\\212\\231H\\305I\\234\\304\\301h\\262i\\014*\\301\\002\\333\\\"\\rZ\\364\\233\\332\\353\\213\\326w:\\245\\324A\\331\\217\\311\\273\\004d-\\210!L\\242\\004\\200\\263\\262\\254\\215o\\333&I\\\"-C\\220\\014\\236\\310#\\n\\254\\033\\377\\367\\277\\352\\306\\371N]\\025\\306\\231MU\\305y6\\032/\\275w\\350\\004H\\320\\210\\202\\245\\276n8\\266n\\270\\333-{\\335\\331l\\205\\016\\275\\007\\301\\264\\265U\\026y\\334\\353\\017\\014\\206\\213\\213\\271l,+\\021\\345\\251o\\\\\\2632\\034\\210~\\344\\356\\277=(\\372o\\231f(\\022\\335\\202Y\\314\\327\\323E\\365\\335\\213\\037\\037}\\366U\\005\\254\\220@\\200\\266\\316\\037\\035m\\377\\346\\341\\003d8?\\237N\\247MS\\033\\327T\\303\\255\\374\\235\\233\\273\\\"(\\277>\\327\\243\\311\\314-*\\347\\321\\362\\202\\230\\205\\367\\250\\244\\224b\\364\\257.-\\252<\\177\\275ut|\\373\\303\\367\\267v\\263\\341\\2416h\\276\\370\\362\\t!\\266\\026@i\\235\\304\\022\\010\\326\\313F\\007\\252\\237e\\211\\n\\241\\335}uz5\\2316\\002\\2476\\014\\376\\374\\365\\345\\342\\315\\270\\314\\262@I-\\225\\'j\\3118b!\\202yE\\270\\236\\242\\277\\342\\357_~}6>\\352)if\\363u\\335\\357\\364:J\\214&\\263\\245\\367ZHYt\\313\\316`\\320\\266\\255\\326\\020\\305\\230\\306\\341\\215\\375=\\337\\2328.\\276\\372\\311\\306n\\361\\366A\\257\\2418\\213\\202<\\216\\227\\353\\225\\347<\\010\\243()\\253\\326V\\365\\nmK\\336\\256/GUx\\250\\252\\326\\264~;O\\377\\251\\320\\177J\\345\\177\\216\\347:\\031\\014\\212\\355-\\031G\\313\\331F\\010\\010%\\263\\246\\270L\\016\\367\\366\\373;\\207\\217\\276\\377\\257\\217Nz\\243\\312\\217F3K\\351\\332\\230(J\\320Y\\255\\240j7\\313z\\215\\344Y@\\231%\\306X\\241\\344\\255\\373\\267\\031\\032\\252\\353\\341jq\\023\\223\\303\\177\\370;\\375\\273\\177\\376\\307n*\\362,\\320{\\275\\326\\330\\2537\\327Q\\020\\304\\375\\336\\322\\352\\361\\313\\305\\325\\325\\354o?:\\032\\277\\270\\316\\013\\021)FK\\221\\216Bb\\262\\336\\241\\r\\002\\031\\311\\310\\032/I \\313\\365\\246=\\270{o\\177\\'\\001\\251[\\364\\237\\3307\\357\\334}\\250WS{\\365\\352\\273\\320\\213A\\021\\235o\\202\\247_\\275\\0161\\212\\373\\013\\022\\301\\360\\336\\307\\211\\216\\377\\360\\371O\\327\\2557^\\264@\\210\\244\\016\\213\\255\\301\\201}s\\331\\314V $HI\\022,\\250\\270\\314t\\226\\032\\214\\306\\013tU\\235\\370\\2653\\347O\\276\\374\\027\\265\\230\\257\\373\\305\\366h\\254\\376\\347\\351\\374\\325\\233VW\\262\\255\\325t\\272\\366\\034\\374\\354\\341o\\357\\334{\\277E\\225&\\275X\\207A\\220\\024yQ\\036\\357\\225;=\\267\\\\\\n\\241\\205\\n\\225\\014TR$\\345 \\355l\\335\\374\\233\\217\\221\\345\\374z\\334\\256jsv\\372\\331\\237\\276\\370\\277\\307\\317\\364jQ\\267\\224,\\243\\336O\\327sA.S\\245\\224\\301\\334To\\037\\036\\345\\316\\335}p\\357W\\037\\177\\264\\331T\\365\\246Z-\\253\\325|5\\231M\\027\\253e{\\247#\\242T\\205y\\020\\306Q\\226\\247e\\336\\033tH\\351\\037\\037\\177Q\\255\\334\\365\\344\\372\\372\\351W\\347\\343\\261A\\251C\\025\\240q\\252\\233W\\336\\006\\242\\270\\371\\336\\007iVn\\265\\346\\356\\255[\\'eg\\200\\315\\311NZus\\203e\\355\\240\\266\\324X\\232m\\254u>\\t\\265\\027B)\\221j\\231\\305b\\273\\320\\317\\177\\270\\234C\\264p\\301\\223\\347/\\316N\\247\\2038(\\272\\251v\\314\\233\\312P\\212a\\234\\004\\\"\\373\\360\\027\\367\\337:9dF^\\273X\\007\\215\\361\\n(U\\220i\\352F\\3021;\\241\\256\\377\\367\\3229z\\367\\203[\\206\\221\\204T\\222#\\205\\022|\\333\\272~\\177\\367\\362j4\\275\\236HteZ\\024\\203\\276\\216\\323^S\\333\\200 \\317\\273\\263\\213\\345\\350\\365E\\240@\\346Y\\365\\370\\351\\253G\\374\\316\\303\\007Gw\\206k&K\\262\\361\\242n\\271u0\\256\\250iQ\\216\\320 \\223`\\224\\240B\\231\\'\\374\\374r2\\371\\346\\247\\365z\\\"<\\223\\367\\363\\332\\341r\\255\\322\\301\\215a?\\334\\336\\037\\316L\\274\\230\\\\\\\\^Ng\\033y\\363\\301m\\232\\317\\032g}gPu\\267Gs<\\233\\320\\350\\032\\257\\256\\332\\325x\\306\\326i\\217\\233\\331f6\\267\\363E\\273\\234\\267\\253\\245\\237,\\350\\345w?L_\\276(;\\031P\\363\\352\\354\\3140T\\306i\\323\\272,\\n\\216\\223kwr\\330\\254\\016\\353\\265\\211;\\372\\370\\347\\267\\336\\377\\365\\273\\007\\021\\377\\361Y\\365o\\277\\277\\214\\330\\0219&/\\320\\023\\326\\210V\\022\\\"X\\007\\202\\020\\030\\200@\\265 \\356|p\\370\\321\\303\\333\\235$\\336\\373l\\367\\333g\\337:\\206\\215\\265\\272\\327\\t\\204t\\343\\313y7\\262\\'\\035<\\255\\354v77m|\\346\\244ME\\276/\\017\\266\\361z\\3320\\263gB\\002\\364\\212P\\022z$\\301\\344\\010\\210\\204\\004EA\\177[\\017nn\\362\\264\\216\\025\\035\\277\\323\\035\\364\\314\\246f!te\\350\\333\\327\\246\\337K\\222\\220\\2430\\277s\\264{4\\334\\337\\314\\251\\235\\341e\\016\\271\\226\\237\\334-%f\\204\\340\\220<\\022:\\337:v\\036\\221\\254G\\004\\000\\0262\\315\\002\\316\\212\\'W|\\366\\254\\2424j\\251\\350\\016\\367\\334t,[\\253\\367\\206\\007;[\\375^\\247+eTf\\335~\\232\\005Q~=\\336\\200\\265i\\032\\275\\\\N\\377\\343\\364\\211vu\\250\\202$\\r\\202@\\013fb\\004\\301\\314\\336{t\\316\\267\\326\\221\\2206\\310\\270w\\004Q\\306Q*z\\351\\340\\360-\\023\\310\\250mt\\247(\\243 f\\206<K\\006\\203N\\273XM\\316.M\\273Mf\\246\\225z\\376\\370\\321\\223/\\376\\210@q\\020\\334\\375\\331\\355\\254\\310\\254\\261L\\350\\321\\021y!\\305l\\271<\\277\\030Yc\\203 |\\367\\227\\277\\351\\035\\275\\215A\\021\\343\\311\\361\\215\\233\\013\\355.G\\027:\\2163%\\203\\235\\255\\335\\335\\235\\341b\\2761\\006M;\\235\\273\\037\\0020\\325r\\362\\342\\233G\\201\\3002\\313\\224\\226\\237\\376\\372\\301\\361\\311\\341b\\325\\\"\\2021\\336\\243M\\263\\350\\311\\323o\\256\\257.E\\024\\324\\363\\331\\350\\273/\\323,\\346\\260\\224B\\346\\3358\\033\\036\\240\\365z\\377\\360(\\213\\223\\303\\375\\275\\315\\2721\\226\\263\\336\\366\\370|\\264Y\\325\\333\\203\\235\\353\\363\\037\\025\\320\\317\\357\\274\\2673\\350\\177\\376\\370\\233?\\374\\376\\337\\367v\\373\\255g\\\"@d\\006\\212\\022\\375\\372\\365y \\345{\\367?\\030\\237\\235Mf\\023\\273Y\\345\\333\\035\\275\\271\\224\\275n\\326\\331\\276w\\257\\247O\\216o\\024Y\\341\\0349vi\\331M\\222\\314\\235\\236\\216\\236?\\303\\341\\361\\364\\354\\305\\240H\\327\\213\\251k6\\276\\256\\377\\373\\363W:\\014\\224\\224D\\336{\\303\\214\\014\\300\\304\\007{\\007\\363\\263W\\211\\326\\335\\262c\\227+.j`\\2635\\270\\345\\235K\\002\\241\\353\\2521\\rn\\r\\266\\262\\\"h\\352V\\353\\250\\354n-\\346\\177>;\\375\\336\\331zS\\364\\254\\251\\221\\300y\\017Rz\\217 \\0043!\\\"\\023\\001\\003\\223\\177sq\\272\\252\\272E\\331\\233O\\256\\306\\027\\257\\322\\227\\337~\\362\\351\\247{\\303\\375\\326\\264\\266Y\\351\\331\\242\\312\\022\\320J1\\031B\\357\\234\\035\\356\\355\\345q|u>S:\\334Tkt\\226\\205\\360\\33623\\010\\301\\204\\300\\014LB00\\203`g\\001\\264\\224JnVs\\017\\\\v\\373\\037~\\370\\213\\\"\\353\\206\\262\\3020\\324\\314\\304L\\233\\2526m\\213\\204\\304A\\250\\203,\\317t\\250\\230\\275w\\236\\231\\005K-\\005\\200\\000!X\\n\\000b\\026 \\030\\000\\004\\010\\000\\266\\255Y-\\247JK\\357\\332\\301\\240Wv\\267Zk\\235\\367\\210\\244\\021\\275u\\355\\252\\332XO\\200\\200\\350\\264\\324\\367\\356?P\\0326\\353\\245s\\316Y\\347\\021\\021\\035\\021\\\"\\022\\222\\007Bb\\002\\000\\001 \\005\\200\\020 \\225\\224Z\\245\\252\\233\\304;{7f\\263\\205\\220\\n\\230\\020Q\\023\\242G\\333\\230\\206X\\n\\026\\336;!y\\177x\\264\\275\\265km\\353\\2343\\306\\030c\\234\\267\\336{kmk\\215\\263\\326\\223#&`\\026\\300$AH\\245\\3038J\\222\\262;8:\\276e\\255\\235\\315gRIb\\322H\\210$[\\333\\002()\\224G\\'\\005!@\\020\\306a\\224H!\\200\\201\\030\\220\\210\\220\\220\\320\\243\\363\\210\\036\\035\\022\\021\\020\\003\\203\\000\\241\\264R\\241\\016\\203 \\014\\245\\0166\\315\\306\\270FH\\311\\000\\032\\311!\\202D\\211\\254\\224\\324\\032A\\313\\300\\223@\\226\\002@\\n\\001,\\230\\001\\231\\210\\230\\350\\257\\367\\260\\020 \\205\\000\\001 \\376\\302\\304L\\336;\\004\\220\\204\\n[\\2554\\010\\001\\000\\032\\230$\\260d\\357\\211\\010\\004\\242\\363\\n\\220\\002!\\231\\211\\244\\220R*bF\\\"\\\"\\\"Fb\\\" \\026\\314\\300\\310\\000\\300\\000B\\010@& \\222,\\231\\000\\255\\363\\002X\\010\\006\\320\\304\\210\\344\\204gbI\\004N\\020\\003;&\\311\\n\\211\\004H\\245\\002)\\244c\\357\\211\\200\\211\\201\\031\\000\\377\\222d\\006f\\t\\202%3#\\023H!\\004y`\\017\\202\\031\\030\\030\\376\\037dO[\\244\\306A\\213\\315\\000\\000\\000\\000IEND\\256B`\\202\"\n",
            "}\n",
            "\n",
            "bytes_list {\n",
            "  value: \"\\211PNG\\r\\n\\032\\n\\000\\000\\000\\rIHDR\\000\\000\\000 \\000\\000\\000 \\010\\002\\000\\000\\000\\374\\030\\355\\243\\000\\000\\010vIDATH\\211E\\226Io\\\\\\307\\025\\205\\357P\\365\\206~\\315\\356&%\\212\\203\\254\\201\\222\\\"\\331\\360\\024\\303\\206\\r\\033\\211WA\\026Y\\004\\371A\\001\\362\\177\\214\\000\\t\\262r\\034 \\253\\004\\361\\3060\\024DNbK\\242Hqj\\221l\\366\\233\\207\\252\\2727\\2136\\224ZT\\341,\\352\\324=8\\213\\372\\360\\361\\277\\237L\\247\\323\\351t\\n\\000\\242\\202\\240\\000@D\\n\\000\\000@\\006\\000\\001@BP\\000R\\r\\301\\253*\\\"\\252*\\002\\262\\022\\000 \\342|>\\237\\315fI\\222\\020\\021\\000\\250*!\\n\\242\\271\\274\\274\\\\[[s\\3161\\263W\\021\\205\\340\\275\\261VB`f\\224.xo\\214\\365\\336\\211h\\222$\\314\\274\\272\\257\\252\\240\\000\\n\\257\\345\\353\\265\\032\\021\\021\\t\\3210s\\333\\266D$\\\"`lP\\350\\272\\316\\030\\243\\252\\226)\\306\\000\\242\\201\\250n\\232\\3618\\033z\\210\\343\\304Z\\253\\252\\242\\252\\\"*\\272J`\\255e\\346\\327\\017\\204\\020\\020Q\\021MQ\\024\\210\\210\\210y\\236G\\351(\\212\\343\\266\\355\\2545\\200\\330y\\027\\257\\245\\303\\320G\\326\\242\\370\\340z\\025\\300(\\016\\33633\\003\\010\\240\\022\\256LEde\\272\\212(\\\"\\252*\\010\\306{\\357\\234;::R\\325\\304\\r6\\262\\3030L&\\023D\\254\\362e\\2678\\023\\t\\323\\351,\\317\\227\\326\\332\\255\\235\\333!J\\211\\231\\000\\020\\020D\\000~\\354`U\\231\\252\\206\\020Tu\\325\\004\\000\\030\\\"*\\212\\\"\\212\\\"\\000\\250\\313|m<\\\"\\221\\276.\\252\\252\\272\\272\\274\\214Qvwv\\272\\272\\314\\222\\330\\030S\\025\\345d\\262a\\230UTAETAVF\\336{\\021\\211\\343x\\325\\277\\210\\000\\200 \\230\\276\\357\\275\\367uSG6J#\\324\\001\\235\\367\\256\\255\\362\\345\\262.\\362\\215\\355m\\t\\3169\\277\\273\\267W\\225e\\335wnp*\\302\\314\\252 *\\200\\204H\\257\\023\\254\\316\\327\\222\\020\\214\\266\\335\\235\\275\\275\\347\\'/\\253\\266v\\036{\\035\\020$6&\\317\\027\\3224|i/\\217^j\\226\\236\\244\\\\\\2265\\340(Q\\300\\361h\\347\\346\\275\\004\\240\\320F\\035$\\306\\246Q\\224\\306\\034\\'\\0301\\212\\\"\\220\\t\\000\\240\\001\\020\\215o\\033?\\370eU\\031\\365\\227\\347\\213\\311\\372\\364\\215\\235\\355\\241,/\\216O\\356mm\\035>yb\\220\\236-/\\262\\303g\\037\\274\\363\\376\\311\\341Q5\\370\\335\\267\\037\\23652\\005\\256\\222\\026[\\000\\266\\224X\\310\\257\\212%}\\377\\342\\354\\356\\303\\267t\\274\\326+\\214\\327\\262\\256\\355M\\335\\267y\\235\\327M5F\\ry>\\236d\\371\\301a\\271XFN\\313\\274\\374\\352\\357\\177\\273\\275\\275\\373\\335\\301\\376\\364\\370\\370\\375\\233\\017O\\037?\\201~pG\\207\\302\\223u\\264]\\334\\331\\001\\241\\357QB\\353\\272\\001\\274\\363\\260\\336\\272\\313(5\\233[nk\\253\\251ks<?\\235\\354n\\357\\354l\\226/\\016\\\\\\275|\\376\\303B\\206\\320\\026\\265s\\3760\\310?\\377\\365\\237\\320\\311g?\\373\\234\\322\\270^\\326q\\333M\\363\\302\\024W\\271\\343\\246\\013\\205[d\\201\\3019\\357\\372\\240^\\r\\016\\210\\373@k\\037}:\\276u\\367\\342\\342\\252\\252\\nc,/\\362\\205\\017\\203_\\\\^<\\177:\\236e\\306\\303\\030\\355\\361\\331|\\357\\316\\336\\247w\\037\\264u\\037\\331\\344\\264\\256y>\\037\\272\\2728\\334O\\245\\0370N%\\332\\231Z\\356\\332\\241k\\213b\\311 \\304\\340T\\302\\342\\326\\255\\335\\033ml\\256\\362+\\347;\\343\\206\\356\\364\\344h1?\\036\\235\\274\\332\\310\\373Q\\336g\\312\\322\\016;\\343\\321\\254\\350f\\353\\327\\037\\277|\\371\\207/\\276\\320\\275\\333}\\023\\266\\253\\345]kc\\365K\\3578\\232\\334\\270v\\335\\006}\\372\\374\\251pP\\r*bA\\353\\362jQ.N\\216\\245\\010\\303\\336\\255\\233&\\215\\242\\203\\371i\\354\\035,\\213]\\215g\\016f\\212\\320\\273\\324h\\\\5\\221\\370~\\373\\372h{s\\261\\275\\375\\303\\263\\323\\252\\251\\304D1\\311\\332,iJw\\226/\\263\\321\\23067\\026G%#\\317F\\343\\304\\207\\363\\262\\374\\362/\\177\\376\\266,6\\267\\326\\303G\\037\\230\\266\\250\\232\\242\\270>\\311\\260\\353[\\rN \\262\\221\\245\\276-\\257h\\000\\357\\234\\010\\265\\245\\271\\010\\370\\352\\305<\\353\\034\\217\\246YD\\355Z\\026(D\\323\\311\\274\\250\\256\\272\\241IR\\003\\220&\\243\\221\\007R;\\264\\275/\\2276\\013G\\337|m\\272\\266\\253\\213\\3628\\317\\315\\\"\\377\\346\\325\\253R\\374^\\226}\\366\\350^[\\224\\340\\272(\\370\\323N\\3526K3#U\\033P\\212\\316\\2357\\213\\343\\352\\352\\332d\\023\\214=\\351\\372o\\367\\017M\\232\\274usk\\224\\216\\252\\203c\\237\\021\\224\\313-\\213\\243\\272\\250\\363\\005\\217F\\351\\213\\375\\203\\242l\\277\\177\\265<\\350\\273&\\213N\\273\\001g[\\2275\\371d\\243\\330\\334\\364[w\\016\\362>\\357\\272l#+\\316O\\337\\333\\330x#Mz\\255\\275wC\\200/\\317O\\256n\\\\+G#\\352\\334zYKW\\353\\230\\275\\035\\326\\257\\2451\\311eQ\\231\\323\\371\\013\\325\\220\\214g\\243\\033\\033i\\035_[K=\\350\\\"\\014\\277\\372\\365/\\357\\354\\336\\3544p4>\\376\\375\\037\\347G\\007\\217\\336}3\\274|\\026\\261\\372\\336\\017\\255\\013HU\\350\\212$;\\367\\232\\332\\370,twG\\243$\\321ab\\037}\\374\\316\\351\\3206\\375p|\\274\\344GoNg\\353#\\t\\276\\251\\233\\373\\351\\364^6\\351]\\303\\023\\363\\360\\343G7\\356o\\357n\\355\\366N\\246\\323\\331\\203\\373\\367\\262\\324\\336\\335\\231\\336\\260`\\010\\362Q\\0246\\266.0:dx\\364\\356\\207\\257\\346\\213\\301;\\037\\333\\331\\235M\\332]?\\016\\356eY\\314\\313\\252\\201\\261\\271}{\\206`N\\216\\256\\020\\373q\\304\\26777\\313\\313\\2722\\376,?\\352\\367+X\\302\\341\\376\\031c<\\233M\\372\\352\\325\\0207\\377M\\252\\253\\227\\347\\323\\373\\267\\276~\\374|qQ\\315\\336\\330\\276\\234\\237\\215\\223\\210\\222\\361?\\016\\237\\276\\367\\213\\337D\\251q\\250\\233\\252(x\\0372so\\357f\\333\\014\\327f[\\007\\373\\347\\305i\\365\\374\\342\\270\\350\\253\\007o?\\\\\\217\\\"m\\252\\266\\353\\306S\\265\\244\\017\\356_\\023\\311\\352$P\\220\\360Y\\220l\\343\\313\\375\\323\\'O\\016n\\r\\345F\\024\\335\\230N\\337\\374\\351{\\337\\355\\217\\322\\315\\033\\306\\330,M\\000\\315\\332h<\\211\\022\\374\\335o\\177\\3354\\375\\336\\235\\267\\016\\017.\\376\\372\\247\\257Rk\\242\\314~\\362\\351\\207\\353k\\231\\367m\\213\\003\\252AE&E\\034\\214\\035\\241F\\250\\326i\\\\t\\220_\\345\\031\\270\\2658\\036eY\\264\\226@j \\020\\252!b\\004\\326 \\240`P\\306\\261\\211OO.\\304\\343\\'\\237\\377\\334X\\236\\255O\\022kb4\\263tCS\\260Q\\232\\304\\tq@\\032R\\237\\002$\\242L\\016\\235W\\271G\\275t\\203\\363\\316{\\357\\274\\357\\304\\001\\272 \\352\\203\\006\\360A<\\032\\363\\306\\356O\\0205\\004042LlI\\020\\030(RB\\037@E\\201\\001P\\3259\\337\\004o{\\200!\\014I/\\344}\\247\\322\\251u\\010\\n\\034adD\\275Q\\033\\221E\\003@>(\\0312W\\213\\032\\t\\020\\220\\331\\023\\2221L\\314\\314\\266\\005\\260\\310\\026\\020P\\t\\010\\321\\022f\\230X\\3136\\\"\\212\\0050\\204Hp\\254V\\0143\\023\\007\\224\\316\\025\\276s*\\226\\r\\002\\r\\336{\\327\\033cck\\r\\02133!\\031\\346(\\212\\230\\231\\231\\230\\310\\020\\306q\\224\\304\\t\\022\\\"\\022\\000\\252\\202\\n\\252\\202s\\342\\235wCp\\336\\205\\336\\265\\316\\r\\316\\271\\240M\\327\\205\\020V\\220!*f:\\233\\0316l\\014\\\"2\\021#!\\341\\n\\233\\020\\000A|\\220\\246\\353T\\025\\020$\\250s\\336\\r\\301{q\\203wne%\\210(\\\"\\316{\\'\\032DWr\\3659\\233\\266\\357\\231\\275\\t\\006\\000\\010\\020\\001T\\025\\221\\230\\010\\tQ\\204\\020\\211\\031TE5\\370\\225\\243\\202R\\010\\240\\242\\n\\000\\200\\253\\235\\210P\\025Q\\376OJ\\022\\314U^Xcmd\\001\\200\\025\\r1\\033F\\000fc\\014\\023! !\\240\\002**[R\\024q\\001\\3100\\243x\\021\\357\\225t5~\\010A\\001C\\010\\3169Uu\\316\\211\\252!\\262HF\\025\\211\\230\\315\\217M !\\263a\\313\\226HA%\\210\\202\\022\\022 \\\"!\\031\\032\\006\\357\\275\\004\\037D\\300{\\207\\210AT\\004\\024\\304\\373\\037\\351\\030\\021\\t\\301 1\\000\\002\\022 )\\220(\\002\\242!\\003\\304\\n$\\000\\\"+\\312R\\'\\203*\\210\\200\\004\\010\\\"\\336\\007\\000\\n\\022\\024He\\305\\332\\004\\032V\\326\\000\\300\\314Hd\\006\\347\\2145\\214\\026\\010\\201\\020\\210\\2000\\250\\250@P\\t*H\\264\\002\\302\\020\\002\\002\\252B\\337;\\000\\022\\005U\\tA\\000\\024\\020AAU\\2108\\216yE\\217\\\"\\002\\210\\377\\003Cf\\323\\360\\000\\327\\252\\004\\000\\000\\000\\000IEND\\256B`\\202\"\n",
            "}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNlFiu2Rzf5C",
        "outputId": "7eff439a-3cb5-487c-afe7-5be647c7818d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "cta = CTAugment(10)\n",
        "#new, choices, bins = cta.augment(image)\n",
        "tf.print(image.shape)\n",
        "new = cta.augment_batch(image)\n",
        "tf.print(new.shape)\n",
        "plt.imshow(new)\n",
        "\n",
        "lab = tf.one_hot(1, 10)\n",
        "pred = tf.random.uniform([10], maxval=1)\n",
        "\n",
        "#cta.update_weights(lab, pred, choices, bins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-492-2a7102435617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTAugment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#new, choices, bins = cta.augment(image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'image' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JAbVTvztHEJ",
        "outputId": "fe75f92c-0547-4791-c7a4-0bc242e39851",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        }
      },
      "source": [
        "cta = CTAugment(10)\n",
        "new, choices, bins = cta.augment(image)\n",
        "plt.imshow(new)\n",
        "\n",
        "lab = tf.one_hot(1, 10)\n",
        "pred = tf.random.uniform([10], maxval=1)\n",
        "\n",
        "cta.update_weights(lab, pred, choices, bins)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([0. 1. 0. 0. 0. 0. 0. 0. 0. 0.], shape=(10,), dtype=float32)\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-66546c3b6c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchoices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-a4268747ab65>\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(self, label, pred, choices, bins)\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m       \u001b[0momega\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: return arrays must be of ArrayType"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1xOtqKpuLZ4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}